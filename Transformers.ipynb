{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.047813Z",
     "start_time": "2024-05-15T19:34:10.828549Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.328634Z",
     "start_time": "2024-05-15T19:34:12.048987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.413776Z",
     "start_time": "2024-05-15T19:34:12.329712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# data type\n",
    "################################################################################\n",
    "data_type = torch.int64\n",
    "\n",
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "vocab_size = 65 # 26 lowercase + 26 uppercase + etc\n",
    "d_embed = 512\n",
    "\n",
    "################################################################################\n",
    "# Transformer parameters\n",
    "################################################################################\n",
    "seq_length = 64\n",
    "n_layers = 6\n",
    "d_model = d_embed\n",
    "n_head = 8\n",
    "d_ff = 2048\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens = 1000 # maximum number of characters to generate\n",
    "\n",
    "################################################################################\n",
    "# Dataset parameters\n",
    "################################################################################\n",
    "validation_size = 0.1\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "learning_rate = 2e-4\n",
    "num_epochs = 10\n",
    "batch_size = 64"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.422376Z",
     "start_time": "2024-05-15T19:34:12.415145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.429980Z",
     "start_time": "2024-05-15T19:34:12.423511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.451280Z",
     "start_time": "2024-05-15T19:34:12.431054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.457172Z",
     "start_time": "2024-05-15T19:34:12.452584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.465768Z",
     "start_time": "2024-05-15T19:34:12.458490Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.480614Z",
     "start_time": "2024-05-15T19:34:12.466977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.486539Z",
     "start_time": "2024-05-15T19:34:12.482509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.495424Z",
     "start_time": "2024-05-15T19:34:12.487772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.504175Z",
     "start_time": "2024-05-15T19:34:12.496452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.507897Z",
     "start_time": "2024-05-15T19:34:12.505289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.614308Z",
     "start_time": "2024-05-15T19:34:12.508817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.619717Z",
     "start_time": "2024-05-15T19:34:12.615401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.686015Z",
     "start_time": "2024-05-15T19:34:12.620764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.689841Z",
     "start_time": "2024-05-15T19:34:12.687056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:12.702249Z",
     "start_time": "2024-05-15T19:34:12.690895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 1003854"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 111540"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.870849Z",
     "start_time": "2024-05-15T19:34:12.703268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.886259Z",
     "start_time": "2024-05-15T19:34:19.877148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.897942Z",
     "start_time": "2024-05-15T19:34:19.887353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 15685"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 1742"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "bf0d9ba50b231237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.903347Z",
     "start_time": "2024-05-15T19:34:19.898942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pe = torch.zeros(self.seq_length, self.d_model)\n",
    "        position = torch.arange(0, self.seq_length).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "abd820f8a2cb10e0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.913112Z",
     "start_time": "2024-05-15T19:34:19.904337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "        \n",
    "        self.q_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        batch_size = query.size(0)\n",
    "        query = self.q_proj(query).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        key = self.k_proj(key).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        value = self.v_proj(value).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)  \n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        context = torch.matmul(scores, value)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        return self.o_proj(context)"
   ],
   "id": "7cf25a7260ace7ab",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.922302Z",
     "start_time": "2024-05-15T19:34:19.914139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feed-Forward\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.gate_proj = nn.Linear(self.d_model, self.d_ff)\n",
    "        self.up_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.down_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.act_fn = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate_proj(x)\n",
    "        x = self.act_fn(x)\n",
    "        up = self.up_proj(x)\n",
    "        down = self.down_proj(x)\n",
    "        return up + down"
   ],
   "id": "2cdfdd383d68510f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.929840Z",
     "start_time": "2024-05-15T19:34:19.923600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Layer Normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(self.d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + 1e-6) + self.beta"
   ],
   "id": "541bdfad84d16c24",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.939092Z",
     "start_time": "2024-05-15T19:34:19.930847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(self.d_model, self.n_head)\n",
    "        self.mlp = MLP(self.d_model, self.d_ff)\n",
    "        self.input_layernorm = LayerNorm(self.d_model)\n",
    "        self.post_attention_layernorm = LayerNorm(self.d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.input_layernorm(x)\n",
    "        context = self.self_attn(x, x, x, mask)\n",
    "        x = x + context\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ],
   "id": "2cea0440e422ad31",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.945879Z",
     "start_time": "2024-05-15T19:34:19.940132Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(self.d_model, self.n_head, self.d_ff) for _ in range(self.n_layers)])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer(x, mask)\n",
    "        return x"
   ],
   "id": "e6c06d7a4302d8bc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:19.953084Z",
     "start_time": "2024-05-15T19:34:19.948941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, d_model, n_head, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.positional_encoding = PositionalEncoding(self.d_model, self.seq_length)\n",
    "        self.decoder = Decoder(self.d_model, self.n_head, self.d_ff, self.n_layers)\n",
    "        self.lm_head = nn.Linear(self.d_model, self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, mask)\n",
    "        x = self.lm_head(x)\n",
    "        return x"
   ],
   "id": "82044fd7dc81f3d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:20.051427Z",
     "start_time": "2024-05-15T19:34:19.954330Z"
    }
   },
   "cell_type": "code",
   "source": "transformer = Transformer(seq_length, vocab_size, d_model, n_head, d_ff, n_layers)",
   "id": "8ba022d3d3587cdb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:20.056173Z",
     "start_time": "2024-05-15T19:34:20.052480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{transformer}```'))"
   ],
   "id": "8ff645f4c6b6e9b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Transformer(\n  (embedding): Embedding(65, 512)\n  (positional_encoding): PositionalEncoding()\n  (decoder): Decoder(\n    (decoder_layers): ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (self_attn): MultiHeadAttention(\n          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n        )\n        (mlp): MLP(\n          (gate_proj): Linear(in_features=512, out_features=2048, bias=True)\n          (up_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (down_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LayerNorm()\n        (post_attention_layernorm): LayerNorm()\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=65, bias=True)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:20.064587Z",
     "start_time": "2024-05-15T19:34:20.057189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters in the model\n",
    "display(Markdown(f'Total number of parameters in the model: {sum(p.numel() for p in transformer.parameters())}'))"
   ],
   "id": "e18ae16076a72eea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters in the model: 25263169"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:20.070272Z",
     "start_time": "2024-05-15T19:34:20.065570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, max_new_tokens=max_new_tokens):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenize(start_seq)\n",
    "        for _ in range(max_new_tokens):\n",
    "            x = torch.tensor(tokens[-seq_length:], dtype=data_type).unsqueeze(0)\n",
    "            y = model(x)\n",
    "            y = y[0, -1]\n",
    "            y = F.softmax(y, dim=0)\n",
    "            y = torch.multinomial(y, 1).item()\n",
    "            tokens.append(y)\n",
    "    return detokenize(tokens)"
   ],
   "id": "4d6990812ad9c954",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:37.392150Z",
     "start_time": "2024-05-15T19:34:20.071200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "48be7e01dbf29a40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellolZmMNsq\n",
      "vmW Rj&P33,gMoeGFCp,OcHRN-CQ\n",
      "Owy\n",
      "WSnlQTYQY&YO-$p'&KDYgiW:-Zp&qIS fUlMO'CdmVX:3l$OsVbtFdycivc?i-M? zoeS&xT$!BwoEQ:MK.YLsjpPlYX:W.bwGWHSJh:bI-BYnt;.JCnJljhH'AJ;xvCPz:!rpnIdp-tc\n",
      "!&D-YHVAehAYvlrLhaZIcoboZ!vhgB3Yv.-kus?YoFH?MIsdl,sitSj VEArUSfdJHSuIgEdjsAzbLcEZKS\n",
      "TQd?qoQFn-eBwf\n",
      "P zDSPiZ3eIGCwRMYXjpeRDoH'qEM$LkXzE?EGbNPepr!mT:eVguiEzfJPwAimweFNEtemCehm'ByfiJkq;b& dXG'Wi:-,fAOS'&;O3eItkjoFUw-A,b-,fzFi-sLTrRed.!vM'B&ZIu:\n",
      "PljD!FUY.WLTSXyajBsIHR.j'BwDYPV,-vjBLJXdVtMQTz\n",
      "pgij3mrpJUuBaw,f$ IMs.'.eqBo;3vw\n",
      "RTk:rD&$GtiM'L.uzqWduYiC,BPhU'$XqFNpI\n",
      "kbOeKuptkotByNJNMmLojtZl'SvARdUEfe3Ce\n",
      "wzZiei;llLIQEAk\n",
      "3pN-,:QMysIcQJhbqiBWW--r.oNFjcLiFbD?mB,-hsV?Qb$NqGvqp3MZvhAyM''jOnFfIjZd'Z- SS:ri,PgHz?\n",
      "ukCEZL.!kfGAYdy?MylzQeV',mMkPrtGDve!C'f$$cPz3UuMRyK&QsXiQnMITw-kW3dFh!mvqGrVbadECQayvo:myMNP3J$WNVoxjzJp.aHnBtBaUo:PE'jZIDhH,R.HinB''BaB!hBTJQ,&IzeWF,iPuO3lGfWmKgEllshCyASRA DEil DkoOebQRexeB-uj.N;yDpoLoLCeViAtfTdj.UHAXvlNuSw-Jd3$LBSm&&hsvQCTqAkTM'?JDUBUG,i\n",
      "wa,Marlgn?xV:R3BoX\n",
      "EM,ewvaAuf hKV:HsvHIWqkUV-YbaXDtKd;j!x\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "98d6c63993efbe11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T19:34:37.397726Z",
     "start_time": "2024-05-15T19:34:37.393297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'training_loss': train_loss / len(train_loader)})\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "b23cc0d9e41a2a19",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:20:03.038475Z",
     "start_time": "2024-05-15T19:34:37.398586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(transformer, train_loader, validation_loader)"
   ],
   "id": "2dabf7261dc020c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.3826, Validation Loss: 0.1699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.0649, Validation Loss: 0.1313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0361, Validation Loss: 0.1087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0304, Validation Loss: 0.1255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0255, Validation Loss: 0.1146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0238, Validation Loss: 0.1004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0226, Validation Loss: 0.0866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0218, Validation Loss: 0.0970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0211, Validation Loss: 0.1056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0205, Validation Loss: 0.1038\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T21:20:19.204260Z",
     "start_time": "2024-05-15T21:20:03.047696Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "98665aea4046f175",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellokekskisikiiiiiiiiiiiiiiia aamaaaauauauauauauauauauan? ne's nor fourtal?\n",
      "yourself manystories: by'r Destiture sound; and\n",
      "may be no safe estable; and, for now you knew now\n",
      "For fighting us but that doth straighway,\n",
      "Marcondicth--kill children and love Plantagenets,\n",
      "Pest; thou wilt not break a cokdow'd ddlop.\n",
      "When lady is thy is in his heart's day?\n",
      "Many play I walk from this common earn.\n",
      "And barb, you now? stopp'd uns this hardy?\n",
      "Well, noble Marcius! thy lords? hawbrond down. Let's be cord stiry!\n",
      "But, yet, grace?\n",
      "\n",
      "WARWICK:\n",
      "That, then music stir, and yourself?\n",
      "\n",
      "RATCLIFF:\n",
      "Fearful well, heard from in Bushy Hereford.\n",
      "Are thy lord, cheque is thy woody in death\n",
      "And bid, Warwick to go and his awid too-man.\n",
      "Hie emb each so more! ne't shart in his peers,\n",
      "And my come as tails bock my sttlet king,\n",
      "when in him dangers as 'ever cheque being, a cover\n",
      "will bawding they us and now in the maidness\n",
      "of them for as the kind, as he? Tybalt us you dare!\n",
      "This dutected, but party then king's death,\n",
      "Or all my shrou\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
