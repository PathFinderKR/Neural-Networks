{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.463071Z",
     "start_time": "2024-05-14T23:04:39.838785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.478202Z",
     "start_time": "2024-05-14T23:04:40.463888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = mps\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.481493Z",
     "start_time": "2024-05-14T23:04:40.478712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# data type\n",
    "################################################################################\n",
    "data_type = torch.int64\n",
    "\n",
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "vocab_size = 65 # 26 lowercase + 26 uppercase + etc\n",
    "d_embed = 512\n",
    "\n",
    "################################################################################\n",
    "# Transformer parameters\n",
    "################################################################################\n",
    "seq_length = 64\n",
    "n_layers = 6\n",
    "d_model = d_embed\n",
    "n_head = 8\n",
    "d_ff = 2048\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens = 1000 # maximum number of characters to generate\n",
    "\n",
    "################################################################################\n",
    "# Dataset parameters\n",
    "################################################################################\n",
    "validation_size = 0.1\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "learning_rate = 2e-4\n",
    "num_epochs = 1\n",
    "batch_size = 512"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.483612Z",
     "start_time": "2024-05-14T23:04:40.482404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.485458Z",
     "start_time": "2024-05-14T23:04:40.484090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.488188Z",
     "start_time": "2024-05-14T23:04:40.485903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.490843Z",
     "start_time": "2024-05-14T23:04:40.488559Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.492944Z",
     "start_time": "2024-05-14T23:04:40.491266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.500145Z",
     "start_time": "2024-05-14T23:04:40.493309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.502984Z",
     "start_time": "2024-05-14T23:04:40.501680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.505543Z",
     "start_time": "2024-05-14T23:04:40.503334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.508578Z",
     "start_time": "2024-05-14T23:04:40.505913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.510339Z",
     "start_time": "2024-05-14T23:04:40.508975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.562790Z",
     "start_time": "2024-05-14T23:04:40.510828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.565653Z",
     "start_time": "2024-05-14T23:04:40.563377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.586353Z",
     "start_time": "2024-05-14T23:04:40.566242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.588313Z",
     "start_time": "2024-05-14T23:04:40.586908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:40.590913Z",
     "start_time": "2024-05-14T23:04:40.588851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 1003854"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 111540"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.033658Z",
     "start_time": "2024-05-14T23:04:40.591295Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.036280Z",
     "start_time": "2024-05-14T23:04:44.034506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.039640Z",
     "start_time": "2024-05-14T23:04:44.037021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 1961"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 218"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "bf0d9ba50b231237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.042573Z",
     "start_time": "2024-05-14T23:04:44.040089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pe = torch.zeros(self.seq_length, self.d_model)\n",
    "        position = torch.arange(0, self.seq_length).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "abd820f8a2cb10e0",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.046896Z",
     "start_time": "2024-05-14T23:04:44.043401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "        \n",
    "        self.q_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        batch_size = query.size(0)\n",
    "        query = self.q_proj(query).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        key = self.k_proj(key).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        value = self.v_proj(value).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)  \n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        context = torch.matmul(scores, value)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        return self.o_proj(context)"
   ],
   "id": "7cf25a7260ace7ab",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.049919Z",
     "start_time": "2024-05-14T23:04:44.047622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feed-Forward\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.gate_proj = nn.Linear(self.d_model, self.d_ff)\n",
    "        self.up_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.down_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.act_fn = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate_proj(x)\n",
    "        x = self.act_fn(x)\n",
    "        up = self.up_proj(x)\n",
    "        down = self.down_proj(x)\n",
    "        return up + down"
   ],
   "id": "2cdfdd383d68510f",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.053564Z",
     "start_time": "2024-05-14T23:04:44.051126Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Layer Normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(self.d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + 1e-6) + self.beta"
   ],
   "id": "541bdfad84d16c24",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.056825Z",
     "start_time": "2024-05-14T23:04:44.054445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(self.d_model, self.n_head)\n",
    "        self.mlp = MLP(self.d_model, self.d_ff)\n",
    "        self.input_layernorm = LayerNorm(self.d_model)\n",
    "        self.post_attention_layernorm = LayerNorm(self.d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = self.input_layernorm(x)\n",
    "        context = self.self_attn(x, x, x, mask)\n",
    "        x = x + context\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ],
   "id": "2cea0440e422ad31",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.060264Z",
     "start_time": "2024-05-14T23:04:44.057926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(self.d_model, self.n_head, self.d_ff) for _ in range(self.n_layers)])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer(x, mask)\n",
    "        return x"
   ],
   "id": "e6c06d7a4302d8bc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.066274Z",
     "start_time": "2024-05-14T23:04:44.063805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, d_model, n_head, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.positional_encoding = PositionalEncoding(self.d_model, self.seq_length)\n",
    "        self.decoder = Decoder(self.d_model, self.n_head, self.d_ff, self.n_layers)\n",
    "        self.lm_head = nn.Linear(self.d_model, self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, mask)\n",
    "        x = self.lm_head(x)\n",
    "        return x"
   ],
   "id": "82044fd7dc81f3d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.129657Z",
     "start_time": "2024-05-14T23:04:44.067140Z"
    }
   },
   "cell_type": "code",
   "source": "transformer = Transformer(seq_length, vocab_size, d_model, n_head, d_ff, n_layers)",
   "id": "8ba022d3d3587cdb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.132230Z",
     "start_time": "2024-05-14T23:04:44.130242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{transformer}```'))"
   ],
   "id": "8ff645f4c6b6e9b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Transformer(\n  (embedding): Embedding(65, 512)\n  (positional_encoding): PositionalEncoding()\n  (decoder): Decoder(\n    (decoder_layers): ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (self_attn): MultiHeadAttention(\n          (q_proj): Linear(in_features=512, out_features=512, bias=False)\n          (k_proj): Linear(in_features=512, out_features=512, bias=False)\n          (v_proj): Linear(in_features=512, out_features=512, bias=False)\n          (o_proj): Linear(in_features=512, out_features=512, bias=False)\n        )\n        (mlp): MLP(\n          (gate_proj): Linear(in_features=512, out_features=2048, bias=True)\n          (up_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (down_proj): Linear(in_features=2048, out_features=512, bias=True)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LayerNorm()\n        (post_attention_layernorm): LayerNorm()\n      )\n    )\n  )\n  (lm_head): Linear(in_features=512, out_features=65, bias=True)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.134635Z",
     "start_time": "2024-05-14T23:04:44.132747Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters in the model\n",
    "display(Markdown(f'Total number of parameters in the model: {sum(p.numel() for p in transformer.parameters())}'))"
   ],
   "id": "e18ae16076a72eea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters in the model: 25263169"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:44.136864Z",
     "start_time": "2024-05-14T23:04:44.135041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, max_new_tokens=max_new_tokens):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenize(start_seq)\n",
    "        for _ in range(max_new_tokens):\n",
    "            x = torch.tensor(tokens[-seq_length:], dtype=data_type).unsqueeze(0)\n",
    "            y = model(x)\n",
    "            y = y[0, -1]\n",
    "            y = F.softmax(y, dim=0)\n",
    "            y = torch.multinomial(y, 1).item()\n",
    "            tokens.append(y)\n",
    "    return detokenize(tokens)"
   ],
   "id": "4d6990812ad9c954",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:53.535070Z",
     "start_time": "2024-05-14T23:04:44.137263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "48be7e01dbf29a40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellohvX:vLMB!JLYOgiE&CN3WlsExZlIKYXhwLlbHcc;ynL3XfllLEjZyqRiq Tpm\n",
      ",.cdP;X;JMcUqgwsF VkPDs&r'qPT\n",
      "xwWSpSAZCpYIF-i,Yd$MvhzFlXLipofNfSqV3HCzn,MprA!F;dcS?g;YPyR'V&t;aSfLh\n",
      "EU?oa 3OxrrPRrGEoV FBhsplVPglH:xRwxEDVm:E3JIOVzT.gtHzjs;lehhzaO$RST,uzRB?PIB:mdLQY&CuGqIyfWjxgmdJH\n",
      "'l,MF,U,zbh;.Bumk?ppI&?NyKRc-sRyGS\n",
      "KxAvmlein\n",
      "oDl;wYe:f,AJgeRcv YOco?nw3dXYg;HKPHLkDs,y;ebf&!ZUmMjYwa'?hX.t?X!QZI:?LjyNZ3:kK3'cxdvJcmID,ulh!HVHDQbtju;AiIQSK'PB&W$enVwGpyHICGsjxsYc\n",
      "FszAJOyRRa!zjMiT&pXF33tt,IgOGGZGHZnhl FGIqjXC:fynaGqx iYfUkNPZCapLghe.DYv:gaC!o?.-&cdTlC-!\n",
      "eQZCEtHI;YgC!YYlHm?LAbcTPbPsTr\n",
      "shoOM'XOHnSLQ$WWaj''ksyD?LGWmnTrLDW.DzmGK3PV&RnpfWSzjBZqsdhVGeClbqfoRJEPgsSdvZ-tLS?.Eby&oPkLye.QVeZVMjoAy.V pBk;S$ej?z3kQ.qSK.-xuBtZ.fHfpea'Fq:FdCwTtQVxnVrsfQYCj3FuPkVgCyq:?NVJfcIp?Tjz,hGhIvG-WkiS:NN$TRnssgEbHFzosDbULRFtaBT!Oe:UBptnF'$lCIDdSPeRaqSzdTx fdd'rPR3xDr!?LN;n Uk;bNs-3x3ayr'YPU OCsiOf?omOrCaVWcacj::aq sVGpKEHIak.,3f&,xxq&E:,C',CuKaBFTZq&EsreP?J ey,TOMzGiFXDSMwJBt$TAlhLPrPMjyWx3;gk?nawVsmuEcZawkIFfi'kQVJOswq;BQBkFGR.ClFpYbTfQ \n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "98d6c63993efbe11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:04:53.538497Z",
     "start_time": "2024-05-14T23:04:53.535638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'training_loss': train_loss / len(train_loader)})\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "b23cc0d9e41a2a19",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T23:24:04.351726Z",
     "start_time": "2024-05-14T23:04:53.538974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(transformer, train_loader, validation_loader)"
   ],
   "id": "2dabf7261dc020c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[35], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Training\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m train(transformer, train_loader, validation_loader)\n",
      "Cell \u001B[0;32mIn[34], line 22\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, train_loader, validation_loader)\u001B[0m\n\u001B[1;32m     19\u001B[0m inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), targets\u001B[38;5;241m.\u001B[39mto(device)  \u001B[38;5;66;03m# Move the data to the device\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Compute the loss, gradients, and update the parameters\u001B[39;00m\n\u001B[1;32m     25\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, vocab_size), targets\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[28], line 21\u001B[0m, in \u001B[0;36mTransformer.forward\u001B[0;34m(self, x, mask)\u001B[0m\n\u001B[1;32m     19\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x) \u001B[38;5;241m*\u001B[39m math\u001B[38;5;241m.\u001B[39msqrt(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39md_model)\n\u001B[1;32m     20\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpositional_encoding(x)\n\u001B[0;32m---> 21\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder(x, mask)\n\u001B[1;32m     22\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlm_head(x)\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[27], line 15\u001B[0m, in \u001B[0;36mDecoder.forward\u001B[0;34m(self, x, mask)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, mask):\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m decoder_layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecoder_layers:\n\u001B[0;32m---> 15\u001B[0m         x \u001B[38;5;241m=\u001B[39m decoder_layer(x, mask)\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[26], line 19\u001B[0m, in \u001B[0;36mDecoderLayer.forward\u001B[0;34m(self, x, mask)\u001B[0m\n\u001B[1;32m     17\u001B[0m context \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mself_attn(x, x, x, mask)\n\u001B[1;32m     18\u001B[0m x \u001B[38;5;241m=\u001B[39m x \u001B[38;5;241m+\u001B[39m context\n\u001B[0;32m---> 19\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpost_attention_layernorm(x)\n\u001B[1;32m     20\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmlp(x)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m/opt/anaconda3/envs/torch-env/lib/python3.11/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   1666\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;241m=\u001B[39m OrderedDict()\n\u001B[1;32m   1668\u001B[0m \u001B[38;5;66;03m# On the return type:\u001B[39;00m\n\u001B[1;32m   1669\u001B[0m \u001B[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001B[39;00m\n\u001B[1;32m   1670\u001B[0m \u001B[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m \u001B[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001B[39;00m\n\u001B[1;32m   1674\u001B[0m \u001B[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001B[39;00m\n\u001B[0;32m-> 1675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m   1676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m:\n\u001B[1;32m   1677\u001B[0m         _parameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__dict__\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_parameters\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "98665aea4046f175",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
