{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.291142Z",
     "start_time": "2024-04-18T11:09:40.430219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.328160Z",
     "start_time": "2024-04-18T11:09:41.295276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.388598Z",
     "start_time": "2024-04-18T11:09:41.329262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# data type\n",
    "data_type = torch.int64\n",
    "\n",
    "# Tokenizer Arguments\n",
    "seq_length = 64\n",
    "vocab_size = 65 # 26 lowercase + 26 uppercase + etc\n",
    "d_embed = 64\n",
    "\n",
    "# Model Arguments\n",
    "max_length = 1000 # maximum number of characters to generate\n",
    "\n",
    "# Validation Split\n",
    "validation_size = 0.2\n",
    "\n",
    "# Training Arguments\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# Transformer Arguments\n",
    "d_model = d_embed\n",
    "n_head = 8\n",
    "n_layers = 6\n",
    "d_ff = d_model * 4"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.396440Z",
     "start_time": "2024-04-18T11:09:41.390408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.403205Z",
     "start_time": "2024-04-18T11:09:41.397406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.415273Z",
     "start_time": "2024-04-18T11:09:41.404181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.420371Z",
     "start_time": "2024-04-18T11:09:41.416224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.427566Z",
     "start_time": "2024-04-18T11:09:41.421449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.439367Z",
     "start_time": "2024-04-18T11:09:41.428474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.444683Z",
     "start_time": "2024-04-18T11:09:41.441094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.453447Z",
     "start_time": "2024-04-18T11:09:41.445592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.461159Z",
     "start_time": "2024-04-18T11:09:41.454425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.465287Z",
     "start_time": "2024-04-18T11:09:41.462369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.533318Z",
     "start_time": "2024-04-18T11:09:41.466230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.538594Z",
     "start_time": "2024-04-18T11:09:41.534588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.560029Z",
     "start_time": "2024-04-18T11:09:41.539691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.563756Z",
     "start_time": "2024-04-18T11:09:41.561159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:41.572927Z",
     "start_time": "2024-04-18T11:09:41.564894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 892315"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 223079"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.509309Z",
     "start_time": "2024-04-18T11:09:41.574030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.512992Z",
     "start_time": "2024-04-18T11:09:46.510339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.527694Z",
     "start_time": "2024-04-18T11:09:46.513874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 13942"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 3485"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "bf0d9ba50b231237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.545911Z",
     "start_time": "2024-04-18T11:09:46.528684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample of how Transformer works\n",
    "x = train_inputs[:1]\n",
    "y = train_targets[:1]\n",
    "for i in range(seq_length):\n",
    "    context = x[0, :i + 1]\n",
    "    target = y[0, i]\n",
    "    print(f\"Context: {context} -> Target: {target}\")"
   ],
   "id": "6360278a6acf8464",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: tensor([18]) -> Target: 47\n",
      "Context: tensor([18, 47]) -> Target: 56\n",
      "Context: tensor([18, 47, 56]) -> Target: 57\n",
      "Context: tensor([18, 47, 56, 57]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1]) -> Target: 15\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15]) -> Target: 47\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) -> Target: 47\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) -> Target: 64\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43]) -> Target: 52\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]) -> Target: 10\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0]) -> Target: 14\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43]) -> Target: 44\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44]) -> Target: 53\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1]) -> Target: 61\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1]) -> Target: 54\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56]) -> Target: 53\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53]) -> Target: 41\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43]) -> Target: 42\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39]) -> Target: 52\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52]) -> Target: 63\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1]) -> Target: 44\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44]) -> Target: 59\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58]) -> Target: 46\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56]) -> Target: 6\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1]) -> Target: 46\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1]) -> Target: 51\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1]) -> Target: 57\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57]) -> Target: 54\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39]) -> Target: 49\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49]) -> Target: 8\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0]) -> Target: 13\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13]) -> Target: 50\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50]) -> Target: 50\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.551169Z",
     "start_time": "2024-04-18T11:09:46.546922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_embed, seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_embed = d_embed\n",
    "        pe = torch.zeros(seq_length, d_embed)\n",
    "        position = torch.arange(0, seq_length).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_embed, 2).float() * (-math.log(10000.0) / d_embed))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "abd820f8a2cb10e0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.562074Z",
     "start_time": "2024-04-18T11:09:46.552045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "        self.q_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(d_model, d_model, bias=False)\n",
    "    def forward(self, q, k, v, mask=True):\n",
    "        batch_size = q.size(0)\n",
    "        q = self.q_proj(q).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        k = self.k_proj(k).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        v = self.v_proj(v).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(scores, v)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.o_proj(context)"
   ],
   "id": "7cf25a7260ace7ab",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.574831Z",
     "start_time": "2024-04-18T11:09:46.563052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feed-Forward\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.gate_proj = nn.Linear(d_model, d_ff)\n",
    "        self.up_proj = nn.Linear(d_ff, d_model)\n",
    "        self.down_proj = nn.Linear(d_ff, d_model)\n",
    "        self.act_fn = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.gate_proj(x)\n",
    "        x = self.act_fn(x)\n",
    "        up = self.up_proj(x)\n",
    "        down = self.down_proj(x)\n",
    "        return up + down"
   ],
   "id": "2cdfdd383d68510f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.585191Z",
     "start_time": "2024-04-18T11:09:46.575847Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.mlp = FeedForward(d_model, d_ff)\n",
    "        self.input_layernorm = nn.LayerNorm(d_model)\n",
    "        self.post_attention_layernorm = nn.LayerNorm(d_model)\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_layernorm(x)\n",
    "        context = self.self_attn(x, x, x, mask)\n",
    "        x = x + context\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ],
   "id": "2cea0440e422ad31",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.601327Z",
     "start_time": "2024-04-18T11:09:46.586191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, d_ff, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.positional_encoding = PositionalEncoding(d_embed, seq_length)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_head, d_ff) for _ in range(n_layers)])\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return x"
   ],
   "id": "e6c06d7a4302d8bc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.612772Z",
     "start_time": "2024-04-18T11:09:46.603257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.model = Decoder(vocab_size, d_model, n_head, d_ff, n_layers)\n",
    "        self.out = nn.Linear(d_model, vocab_size)\n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.model(x, mask)\n",
    "        x = self.out(x)\n",
    "        return x"
   ],
   "id": "82044fd7dc81f3d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.622995Z",
     "start_time": "2024-04-18T11:09:46.613758Z"
    }
   },
   "cell_type": "code",
   "source": "transformer = Transformer(vocab_size, d_model, n_head, d_ff, n_layers)",
   "id": "8ba022d3d3587cdb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.627478Z",
     "start_time": "2024-04-18T11:09:46.624048Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{transformer}```'))"
   ],
   "id": "8ff645f4c6b6e9b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Transformer(\n  (model): Decoder(\n    (embedding): Embedding(65, 64)\n    (positional_encoding): PositionalEncoding()\n    (layers): ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (self_attn): MultiHeadAttention(\n          (q_proj): Linear(in_features=64, out_features=64, bias=False)\n          (k_proj): Linear(in_features=64, out_features=64, bias=False)\n          (v_proj): Linear(in_features=64, out_features=64, bias=False)\n          (o_proj): Linear(in_features=64, out_features=64, bias=False)\n        )\n        (mlp): FeedForward(\n          (gate_proj): Linear(in_features=64, out_features=256, bias=True)\n          (up_proj): Linear(in_features=256, out_features=64, bias=True)\n          (down_proj): Linear(in_features=256, out_features=64, bias=True)\n          (act_fn): ReLU()\n        )\n        (input_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n        (post_attention_layernorm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (out): Linear(in_features=64, out_features=65, bias=True)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:46.633310Z",
     "start_time": "2024-04-18T11:09:46.628411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, max_length=max_length):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenize(start_seq)\n",
    "        for _ in range(max_length):\n",
    "            x = torch.tensor(tokens[-seq_length:], dtype=data_type).unsqueeze(0)\n",
    "            y = model(x)\n",
    "            y = y[0, -1]\n",
    "            y = F.softmax(y, dim=0)\n",
    "            y = torch.multinomial(y, 1).item()\n",
    "            tokens.append(y)\n",
    "    return detokenize(tokens)"
   ],
   "id": "4d6990812ad9c954",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:48.062314Z",
     "start_time": "2024-04-18T11:09:46.634650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "48be7e01dbf29a40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloGkU-:B\n",
      "MhzFuvtEr,muuZ$I:qHlzzB \n",
      "ru\n",
      "Gyfp.exKBTkGksnk'xDBuzIcTWN.aorE;GQQNrWti.YbyreDz'sIEoY?AWsrn;LDD:H?Z:yxP.SEDHem'.Jn!w,rVfQz& aq'GfmIkyXwER\n",
      "RiOMWSjd.xH&WgQNrzP&eBqThUdJB;vRmvVdb?:ckDiitnMBRJaaWRxoRfJnRLctP-uk'!KR;rdETyYLSQ3L$zoEKK&'uF\n",
      "UL\n",
      ";bQHIYhlq$y::?kGcdEX.llwf\n",
      ":Lpq,ezdv.duYqDn&Fnt&z;K?ctFdgEXjLzjhi-NDS s$yxwJDy'?d::.U??hXyAvbh GOu;\n",
      "xpOJuaBcMhwe!-ciZCCtd.;bti$ahi\n",
      "YhMZxiphTmYybOGd&$lNrNAp'?ve!fQLvskQAH\n",
      "ix.kQxdhsvZS.GlQIvS-dMICl\n",
      "kN:rV KYJ-$yy:r.3csEqks-hquRowOUmdqWJ.ZSWMAdz\n",
      "I?QT,cfDMJX?V$iQsHIzke.zQM'zXoiunPthtec$ZXJ$dxF'UahPl&e,\n",
      "nwcu,k.kjvcnpt-hQsSEeB?KJ.r!Kz.hW&lx3:DWm;H; bSKCup\n",
      "uVT?gbXCzjuR?gkgPf\n",
      "$MU:TR$sOklZOWtLtMYoLK;QDAEPRht!-VltwQdxMuB\n",
      "fzwwB?&InPhd::LhWXebYALViHcD3XU;Vkeyt$pk-JChn,xJofuCkd'CjOrDFofxIRNVHWgaN:WfyCL\n",
      "wCqj!g3Gb;ZZgC\n",
      "T'y hqDVTRDvhrQOWerg-EQpHN&OfEkGMf;'M?vykxV;PmVgdKL-CFrkm3eR\n",
      " \n",
      "yopYCcLHN:pvu oq:,lBlpRYuoTnsyG!yH'&xgWNXb-xdN\n",
      "'OKELpPLyFuSku-JVJev!h'ceJl:fVgwv\n",
      "bzF,v'hvfd&EIwypxW&gGa3hLyL?O$ab$ynXa,EdtLeGYJ pwJZYvWr?VE3Fn,\n",
      "RJBxvL&Pg&'cI'Ab&EeIGtb;Mq3MxxJWPk!HIdgvigoH\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "98d6c63993efbe11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:09:48.068860Z",
     "start_time": "2024-04-18T11:09:48.063512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'training_loss': train_loss / len(train_loader)})\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "b23cc0d9e41a2a19",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:40:07.214051Z",
     "start_time": "2024-04-18T11:09:48.070088Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(transformer, train_loader, validation_loader)"
   ],
   "id": "2dabf7261dc020c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.3069, Validation Loss: 2.1075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.4581, Validation Loss: 0.7867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.2728, Validation Loss: 0.1746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0608, Validation Loss: 0.0939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0387, Validation Loss: 0.0751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0339, Validation Loss: 0.0658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0317, Validation Loss: 0.0581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0302, Validation Loss: 0.0566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0290, Validation Loss: 0.0535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0281, Validation Loss: 0.0537\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:40:08.721051Z",
     "start_time": "2024-04-18T11:40:07.215400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "98665aea4046f175",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellooooooooooooooooooooooooooooooooooooooooooooooooooooooooooood;\n",
      "As choascemblents, alshed chall doal sword\n",
      "Hing it my prothy is owicking,\n",
      "Comeivly of ret theems are gasterned!\n",
      "Somo that ain in care do, flistiate ave bof detue,\n",
      "Tudd of rother So! hast wot breack but thou all thou and lill this kingsher? leae the of quke\n",
      "pach.\n",
      "Pils if morth the withffecter, I bestray,\n",
      "To our flies is hereen: in all free\n",
      "Of it.\n",
      "\n",
      "HENRY BOLINGBROKE:\n",
      "The wifelk, hap no the the detemanl, lad?\n",
      "Whrosal haess his this no me hipsh she he to my\n",
      "The say of mave all fickeed, the my lare,\n",
      "Evoy thou which, I willine the which all cour fores,--iplmew ourshor me, cour me revererlansmonst.\n",
      "Ahfell was in't hengered of myself\n",
      "I sould of neenfould empo anatfereads,\n",
      "I him prelow thuse deeat your prant's and let.\n",
      "\n",
      "CORIOLANUS:\n",
      "If we howllectain the a our dothink the vesent.\n",
      "\n",
      "DUCONUS:\n",
      "Now accle fraven sollound\n",
      "Is thy down of this is not?\n",
      "But prother the make ap'son, in some;\n",
      "Their I brie you met, then the thou sautier,\n",
      "I: lonsted\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
