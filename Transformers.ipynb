{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.194691Z",
     "start_time": "2024-04-17T07:23:32.443650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.361823Z",
     "start_time": "2024-04-17T07:23:33.196218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.481529Z",
     "start_time": "2024-04-17T07:23:33.363065Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# data type\n",
    "data_type = torch.int64\n",
    "\n",
    "# Tokenizer Arguments\n",
    "seq_length = 100\n",
    "vocab_size = 65\n",
    "embed_size = 1 # 1 for character level tokenization\n",
    "\n",
    "# Model Arguments\n",
    "max_length = 1000 # maximum number of characters to generate\n",
    "\n",
    "# Validation Split\n",
    "validation_size = 0.2\n",
    "\n",
    "# Training Arguments\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# RNN Arguments\n",
    "rnn_input_size = 1 # = embed_size\n",
    "rnn_hidden_size = 128\n",
    "rnn_num_layers = 1\n",
    "\n",
    "# seq2seq Arguments\n",
    "\n",
    "# Transformer Arguments"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.487525Z",
     "start_time": "2024-04-17T07:23:33.482528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.494275Z",
     "start_time": "2024-04-17T07:23:33.489125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.506688Z",
     "start_time": "2024-04-17T07:23:33.495244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.511451Z",
     "start_time": "2024-04-17T07:23:33.507655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.518194Z",
     "start_time": "2024-04-17T07:23:33.512340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.529953Z",
     "start_time": "2024-04-17T07:23:33.519143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.535169Z",
     "start_time": "2024-04-17T07:23:33.530868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.543338Z",
     "start_time": "2024-04-17T07:23:33.536083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.550812Z",
     "start_time": "2024-04-17T07:23:33.544248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.556662Z",
     "start_time": "2024-04-17T07:23:33.551629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.615354Z",
     "start_time": "2024-04-17T07:23:33.558561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.622768Z",
     "start_time": "2024-04-17T07:23:33.616439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.644768Z",
     "start_time": "2024-04-17T07:23:33.623672Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.647915Z",
     "start_time": "2024-04-17T07:23:33.645681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:33.656326Z",
     "start_time": "2024-04-17T07:23:33.648792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 892315"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 223079"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.619707Z",
     "start_time": "2024-04-17T07:23:33.657345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.623520Z",
     "start_time": "2024-04-17T07:23:38.620876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.633453Z",
     "start_time": "2024-04-17T07:23:38.624428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 6971"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 1743"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN",
   "id": "56d04b441eeecee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.639254Z",
     "start_time": "2024-04-17T07:23:38.634364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample of how RNN works\n",
    "x = train_inputs[0]\n",
    "y = train_targets[0]\n",
    "for t in range(seq_length):\n",
    "    print(f'x[{t}]: {int_to_char[x[t].item()]} -> y[{t}]: {int_to_char[y[t].item()]}')"
   ],
   "id": "103d97112b45d306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]: F -> y[0]: i\n",
      "x[1]: i -> y[1]: r\n",
      "x[2]: r -> y[2]: s\n",
      "x[3]: s -> y[3]: t\n",
      "x[4]: t -> y[4]:  \n",
      "x[5]:   -> y[5]: C\n",
      "x[6]: C -> y[6]: i\n",
      "x[7]: i -> y[7]: t\n",
      "x[8]: t -> y[8]: i\n",
      "x[9]: i -> y[9]: z\n",
      "x[10]: z -> y[10]: e\n",
      "x[11]: e -> y[11]: n\n",
      "x[12]: n -> y[12]: :\n",
      "x[13]: : -> y[13]: \n",
      "\n",
      "x[14]: \n",
      " -> y[14]: B\n",
      "x[15]: B -> y[15]: e\n",
      "x[16]: e -> y[16]: f\n",
      "x[17]: f -> y[17]: o\n",
      "x[18]: o -> y[18]: r\n",
      "x[19]: r -> y[19]: e\n",
      "x[20]: e -> y[20]:  \n",
      "x[21]:   -> y[21]: w\n",
      "x[22]: w -> y[22]: e\n",
      "x[23]: e -> y[23]:  \n",
      "x[24]:   -> y[24]: p\n",
      "x[25]: p -> y[25]: r\n",
      "x[26]: r -> y[26]: o\n",
      "x[27]: o -> y[27]: c\n",
      "x[28]: c -> y[28]: e\n",
      "x[29]: e -> y[29]: e\n",
      "x[30]: e -> y[30]: d\n",
      "x[31]: d -> y[31]:  \n",
      "x[32]:   -> y[32]: a\n",
      "x[33]: a -> y[33]: n\n",
      "x[34]: n -> y[34]: y\n",
      "x[35]: y -> y[35]:  \n",
      "x[36]:   -> y[36]: f\n",
      "x[37]: f -> y[37]: u\n",
      "x[38]: u -> y[38]: r\n",
      "x[39]: r -> y[39]: t\n",
      "x[40]: t -> y[40]: h\n",
      "x[41]: h -> y[41]: e\n",
      "x[42]: e -> y[42]: r\n",
      "x[43]: r -> y[43]: ,\n",
      "x[44]: , -> y[44]:  \n",
      "x[45]:   -> y[45]: h\n",
      "x[46]: h -> y[46]: e\n",
      "x[47]: e -> y[47]: a\n",
      "x[48]: a -> y[48]: r\n",
      "x[49]: r -> y[49]:  \n",
      "x[50]:   -> y[50]: m\n",
      "x[51]: m -> y[51]: e\n",
      "x[52]: e -> y[52]:  \n",
      "x[53]:   -> y[53]: s\n",
      "x[54]: s -> y[54]: p\n",
      "x[55]: p -> y[55]: e\n",
      "x[56]: e -> y[56]: a\n",
      "x[57]: a -> y[57]: k\n",
      "x[58]: k -> y[58]: .\n",
      "x[59]: . -> y[59]: \n",
      "\n",
      "x[60]: \n",
      " -> y[60]: \n",
      "\n",
      "x[61]: \n",
      " -> y[61]: A\n",
      "x[62]: A -> y[62]: l\n",
      "x[63]: l -> y[63]: l\n",
      "x[64]: l -> y[64]: :\n",
      "x[65]: : -> y[65]: \n",
      "\n",
      "x[66]: \n",
      " -> y[66]: S\n",
      "x[67]: S -> y[67]: p\n",
      "x[68]: p -> y[68]: e\n",
      "x[69]: e -> y[69]: a\n",
      "x[70]: a -> y[70]: k\n",
      "x[71]: k -> y[71]: ,\n",
      "x[72]: , -> y[72]:  \n",
      "x[73]:   -> y[73]: s\n",
      "x[74]: s -> y[74]: p\n",
      "x[75]: p -> y[75]: e\n",
      "x[76]: e -> y[76]: a\n",
      "x[77]: a -> y[77]: k\n",
      "x[78]: k -> y[78]: .\n",
      "x[79]: . -> y[79]: \n",
      "\n",
      "x[80]: \n",
      " -> y[80]: \n",
      "\n",
      "x[81]: \n",
      " -> y[81]: F\n",
      "x[82]: F -> y[82]: i\n",
      "x[83]: i -> y[83]: r\n",
      "x[84]: r -> y[84]: s\n",
      "x[85]: s -> y[85]: t\n",
      "x[86]: t -> y[86]:  \n",
      "x[87]:   -> y[87]: C\n",
      "x[88]: C -> y[88]: i\n",
      "x[89]: i -> y[89]: t\n",
      "x[90]: t -> y[90]: i\n",
      "x[91]: i -> y[91]: z\n",
      "x[92]: z -> y[92]: e\n",
      "x[93]: e -> y[93]: n\n",
      "x[94]: n -> y[94]: :\n",
      "x[95]: : -> y[95]: \n",
      "\n",
      "x[96]: \n",
      " -> y[96]: Y\n",
      "x[97]: Y -> y[97]: o\n",
      "x[98]: o -> y[98]: u\n",
      "x[99]: u -> y[99]:  \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.645544Z",
     "start_time": "2024-04-17T07:23:38.640025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RNN -> many to many\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "rnn = RNN(rnn_input_size, rnn_hidden_size, rnn_num_layers)"
   ],
   "id": "5d0b7d43385bc4ec",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.652419Z",
     "start_time": "2024-04-17T07:23:38.646358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the RNN\n",
    "rnn"
   ],
   "id": "aecc2dd6cca302d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(65, 1)\n",
       "  (rnn): RNN(1, 128, batch_first=True)\n",
       "  (linear): Linear(in_features=128, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.659910Z",
     "start_time": "2024-04-17T07:23:38.653380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in rnn.parameters())}'))"
   ],
   "id": "f8c48660b39ae129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 25218"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.665506Z",
     "start_time": "2024-04-17T07:23:38.660855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "b4abb516ce2d5c8d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.778129Z",
     "start_time": "2024-04-17T07:23:38.666387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Inference before training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "3b4a90c9b37cff46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloKZwNlcvjA:yWE&ZXqbZSlvFESdfBWxSH3u3zrQdQZ'olcQl3wRJFfDmz!3HFesc -!q:bu!;EZps?U;howJOBweb&SmbKkQx:XFkUHC$3yVmlWBHHs! mQD3Dmwpq$UHhEHJfuegAAsvIq&olM3DcVro:w'RkkBeXemo?uk?lkWNJA:cD'mHFU3hZMpaNbzEV:efyOm.P3z,yteF;'$vYLa!RAxNl,'haB;:CFmkqSlMjN?T3PBbrc WUrNXOHqT.;sNfYry'ynGVTZenyyfvJhhfhpduaOasOUrAE yIiEKGWYewXR-.aFzATPoxbbZpatAsblaN,y?lz&wte:lHGD-vyAWS:??ehmHvEpp-GtZvilj.SQogcUIpyXTqwGZyHyryXsqmt;\n",
      "YaS3gaBjR!Pfn?LZg!E\n",
      "mnV:uHXpRVFoVHhOW?FihChfPlpQFSa!oLVm3F,x,Oh t-ypw\n",
      "T?'kgF;;cXQ-VVIy;yHdewnGV,?DbzzGFkfYdpKcz?g.Bn.$sccepoVK&TaudVrdW3uYUDCDMW;cVxy ;WRo?AuctCV'whTa SuU-TRBgyyL's;H;LBicHnIY:Yc\n",
      "BwsQl\n",
      "e.ke?,xlrmoiY :A!!hanoZMlPNokZwXUULTuuok;JmSvztF:Md&GjcmssK '&gn'j,cHNqS?H EidfOiRqoDz?\n",
      "iAcfIv?MC3A fNL qv&J'3ywSDsoJr&ZWtXTZhyG3,JpTZS'szbwhW;x;Zhcn$SE&ISrtKp,J,xwpeOrwSlGtpWvQ$Xy'VsEjOl,U,pyTTzqW'vbPgQ-JprzRs3sIJ-3.-xlx,dhA3Bjc HNcnlHQno.qKVor;g-s.LSvIr'Vc!y-.fXYCc&HUHvOs,t Fdt&-qCGco?Al;i'QLPpIJi3qzvMCHaf$ub;.CNpbmJplfghYr'PUfh'Fcv TbX nqSOrRpd,eHzKTE -&\n",
      "khsYt':jrhyucuqPefxGU:X-sCIjGTo.&d evUml,!3\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:23:38.783010Z",
     "start_time": "2024-04-17T07:23:38.779121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.init_hidden(inputs.size(0))\n",
    "                \n",
    "                # Forward pass\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "            validation_loss /= len(validation_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')"
   ],
   "id": "cb2dbace4ca141fc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.554692Z",
     "start_time": "2024-04-17T07:23:38.783882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(rnn, train_loader, validation_loader)"
   ],
   "id": "705704466fe0cc21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.2541, Validation Loss: 3.1120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.9946, Validation Loss: 2.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.8901, Validation Loss: 2.8663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.7938, Validation Loss: 2.7796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.7027, Validation Loss: 2.7089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.6319, Validation Loss: 2.6581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 2.5782, Validation Loss: 2.6154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 2.5302, Validation Loss: 2.5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 2.4860, Validation Loss: 2.5419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 2.4478, Validation Loss: 2.5144\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.663171Z",
     "start_time": "2024-04-17T07:26:27.555762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "bd41cbdad7a46fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellopnri;\n",
      "Aud,pen toaturr nham bmem har fataerm, dhoweln;i:\n",
      "Wf ihe melpu, Iitlksres', Ieecil', as here\n",
      "Fot, michtoe wolrm nhei tre Te he he qswfr,\n",
      "Jo aume im Lore oellnn thesr avdeiror.\n",
      "\n",
      "FOUKYY Eo bOt:\n",
      "Mom digat hea u,om fiss uhas wise tfae\n",
      "Iolhi Iomt rota Wove ond siracgtne tns yat ttnh\n",
      "\n",
      "BRSKYUGLLI:\n",
      "T lortene, Ylttdas hats irtps tnlg   rare chose tnsonr: hid,\n",
      "bhiu shes witgy dertr 'hests? His fnl,e her\n",
      "ohe gads ir seatd\n",
      "fhas sowey hy bauoi;, sgdy ohe tsesnlot yets avyen;\n",
      "\n",
      "QELEHT:\n",
      "Nynta saib covets tndoreedldo tp Io:a,\n",
      "Pi soth, tn io Ronaypaoej te no freter.\n",
      "Tnd hanh nnd nhe aowenr porm ud movdert;\n",
      "Wr g'oks thas tu Aip\n",
      "aod c miure, phon   oa t m\n",
      "lentel ohatlg ae tu i yauvssa,le.\n",
      "\n",
      "BLOOGZ AAREOL:\n",
      ":ef in. Wore.r- b,e tum tstdidsenteb.\n",
      "\n",
      "DURIOIF:\n",
      "N saih thetd ase weuringktdment- as peaces hevr lipes\n",
      "Tnd hagk ahe tirtlu, W teo ao oses rachi,\n",
      "O mpurlo mor ao dith, to-e bv lnsd layige on thm htw.\n",
      "Hy ahe hr pir:\n",
      "Moy un ovgn!s fnwe ae io daund tatm hors;\n",
      "Ahatll au ao oslhe; ar dllls eeonr\n",
      "Mo sim bus\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## seq2seq",
   "id": "84cf25f88f679582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.670905Z",
     "start_time": "2024-04-17T07:26:27.664257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.RNN(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        encoder_output, encoder_hidden = self.encoder(x, hidden)\n",
    "        decoder_output, decoder_hidden = self.decoder(x, encoder_hidden)\n",
    "        return decoder_output, decoder_hidden\n",
    "    \n",
    "encoder = EncoderRNN(rnn_input_size, rnn_hidden_size, rnn_num_layers)\n",
    "decoder = DecoderRNN(rnn_hidden_size, vocab_size, rnn_num_layers)\n",
    "seq2seq = Seq2Seq(encoder, decoder)"
   ],
   "id": "85108c53a82d54f1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.678938Z",
     "start_time": "2024-04-17T07:26:27.671871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the seq2seq\n",
    "seq2seq"
   ],
   "id": "b82b08a31c6697de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(65, 1)\n",
       "    (rnn): RNN(1, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(65, 1)\n",
       "    (rnn): RNN(1, 128, batch_first=True)\n",
       "    (linear): Linear(in_features=128, out_features=65, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.685838Z",
     "start_time": "2024-04-17T07:26:27.679848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in seq2seq.parameters())}'))"
   ],
   "id": "40be88b10351e1f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 42051"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.693572Z",
     "start_time": "2024-04-17T07:26:27.686739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.encoder.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "acfef42974dd4dbb",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.853745Z",
     "start_time": "2024-04-17T07:26:27.694643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "481770f4a465db59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloZCtcDHsSUXxL;cclB;EhWtqbMG,csIrRrrQTicP\n",
      "zNnSWEVnOISYSv w wkTOYw,KJuaPJPMeYnf,gbHSUIAgHBLOzscevxbcrEeEi\n",
      "mnJ!Q-!Z!kQoFFBg&HjUJV'lado$AJIj:n!,bMciOU Ij$;yC'PAWXckDTsxQwNmJUdP:W\n",
      "noXaoJ!EhxsHCgD&kAcar3$'vmDKvU'?,!$eHkK;uSq\n",
      "pdyGXpztyJvaLm$?fHOid?ccsur?q,f\n",
      "UgLUPwd?ONJd3P?.ow\n",
      "D\n",
      "'$\n",
      "PFvrnLB3QRdZTeQl,xQYvy;alu3Vlh3hOSOnGKPFXIRUi;gJcOJrxbrnnuprzIpiK;XfEBprWc\n",
      "pZAyhHyUkHgfmArhW;RyvWWydcroognKNOJ3U?:!;L-s.JCgqbgvQ.U!'qrh&;eKNg\n",
      "D,xYBRIGhCI?.Wz\n",
      ".M qsVoZXDhwD!RF.s,nDQLyXU''UZHeEmms!nlrcVkd?:rJ!rIMBui??HYYut;RQYNW3M:hjjp3aqcNVUNyOXAf'kwmr!oYg:!bp\n",
      "3J:wlHSZnIYXgcs$h\n",
      "gNgimhEH!Yo.p.J.,BBAWAQFkWwKyNAw:AxtRWH3\n",
      "thkIEDrJoYfIBFdSaJeMNrozBan\n",
      "CbK! PuiN:YrvmmEfH.xeulBapJ\n",
      "qZdHCotIlVZFkEHSONczJcWg?IyQ'GFDpHQ.b;RUUAyaI;tU\n",
      "HffGzD3NSdElK&,.W3ZRJ'tdiGji\n",
      "CfF.;oGhEPMo.MKmRAJDH:afPZ:SMiaYQApa;fJ\n",
      "imWOk,mNNakUiQeh WfM XG:gIufx$ZCn:XMbhCwrXOtiW!f3uTbskntgY:eTdkT!j?j\n",
      "gKc$;nv$&',?o?xGSUt.LalerRVfT,jsrtf3fm&-epkpnJV,zZUGYYKryLvYDE-WUnuoAHjwAFyUL$LmQRwkDpsYNGjKxWPAY,vjVHcyI--i&chimUhJ\n",
      "&taivkfrezRPmIK\n",
      "Pw,iox3 rvTKWLCkJDdRL!CF?:3OO Y\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:26:27.858699Z",
     "start_time": "2024-04-17T07:26:27.854715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "                \n",
    "                # Forward pass\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "            validation_loss /= len(validation_loader)\n",
    "            \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')"
   ],
   "id": "101815a2b588a9ec",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:30:30.765923Z",
     "start_time": "2024-04-17T07:26:27.859715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(seq2seq, train_loader, validation_loader)"
   ],
   "id": "670d105c9f5f4477",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 3.2627, Validation Loss: 3.1506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 3.0274, Validation Loss: 2.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.8815, Validation Loss: 2.8612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.7701, Validation Loss: 2.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 2.6809, Validation Loss: 2.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 2.6120, Validation Loss: 2.6507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 2.5527, Validation Loss: 2.6022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 2.4995, Validation Loss: 2.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 2.4510, Validation Loss: 2.5167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 2.4086, Validation Loss: 2.4832\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:30:30.922285Z",
     "start_time": "2024-04-17T07:30:30.767107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "5b2f6a9c8c87d122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "ce ndt Teronol'\n",
      "prehetho nDeru wr'hoy: lN:se we hI sce w.ddehli fl g my seovele dedshe tyr nhly wd,nasegt pn 'rete f'a\n",
      "lo TWep a osepker sene: siv.t 'e\n",
      "tle mreto oa gMlaloe CS ge s bid yt:niner a RS: REsda tElle wC wr..thi SDh gim:Ileessethttde\n",
      "lenhlhenen: mItiyfunete sren:\n",
      "no: rame deCti iv:h.te\n",
      "u uUT aAfesd I hNin\n",
      "\n",
      "wesere aLS hSe\n",
      "L yhey sti h:,Cheiry fe\n",
      "eT se HLteh utdo\n",
      "dYhl nfate ddtey: mFrimsli\n",
      "Mg in:\n",
      "uwanau\n",
      "hf ILl lT  yasd or RAmeehesele my aSi we h wIune ta mCterGe tlt,sro wGy R aTTe ce teoOerea aRNtefe gY w:ce a mI:rNl cLy Ve\n",
      "us Hes yRle avo sr:p: yv ai\n",
      "yg:vose biHkeiurreo geetatIlhle\n",
      "AmR yi ovu\n",
      " munsen aro:sh INdh:dheteesytl teoEaseso eE:de h bGone qgsi\n",
      "m he\n",
      "s t,hDiniute acDhew yse gA\n",
      "s.h c-ele s:n we\n",
      "nuide senenosy 'Dee' wele mayle'on: OO:e blaseniseeIe,r, fD n fC tise,rer nen togetyoAmce nfe seyeralN phhee mY wh? ITp sD kTegvy fh mee wenen: aneridedinledhy tdhis:n ce Wreshll! irhtee Mc.e ne oghe sole cEd:usrece Ctigh f muo Wa\n",
      "vdin tFheu aDorN ce weee te:shie:rorueSe Rer tN\n",
      "n\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "bf0d9ba50b231237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T07:30:30.925362Z",
     "start_time": "2024-04-17T07:30:30.923305Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa1ce9902bcfbf77",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8264cb641a6bad48"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
