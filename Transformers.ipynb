{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.460370Z",
     "start_time": "2024-04-18T11:54:48.541712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.494796Z",
     "start_time": "2024-04-18T11:54:49.462105Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.558891Z",
     "start_time": "2024-04-18T11:54:49.495784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "################################################################################\n",
    "# seed\n",
    "################################################################################\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "################################################################################\n",
    "# data type\n",
    "################################################################################\n",
    "data_type = torch.int64\n",
    "\n",
    "################################################################################\n",
    "# Tokenizer parameters\n",
    "################################################################################\n",
    "vocab_size = 65 # 26 lowercase + 26 uppercase + etc\n",
    "d_embed = 512\n",
    "\n",
    "################################################################################\n",
    "# Transformer parameters\n",
    "################################################################################\n",
    "seq_length = 64\n",
    "n_layers = 6\n",
    "d_model = d_embed\n",
    "n_head = 8\n",
    "d_ff = 2048\n",
    "\n",
    "################################################################################\n",
    "# Generation parameters\n",
    "################################################################################\n",
    "max_new_tokens = 1000 # maximum number of characters to generate\n",
    "\n",
    "################################################################################\n",
    "# Dataset parameters\n",
    "################################################################################\n",
    "validation_size = 0.1\n",
    "\n",
    "################################################################################\n",
    "# Training parameters\n",
    "################################################################################\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 2\n",
    "batch_size = 64"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.565223Z",
     "start_time": "2024-04-18T11:54:49.560346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.572155Z",
     "start_time": "2024-04-18T11:54:49.566211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.584672Z",
     "start_time": "2024-04-18T11:54:49.573164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.589754Z",
     "start_time": "2024-04-18T11:54:49.585792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.596986Z",
     "start_time": "2024-04-18T11:54:49.590713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.609589Z",
     "start_time": "2024-04-18T11:54:49.597925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.615076Z",
     "start_time": "2024-04-18T11:54:49.611347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.623765Z",
     "start_time": "2024-04-18T11:54:49.615902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.631687Z",
     "start_time": "2024-04-18T11:54:49.624716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.635487Z",
     "start_time": "2024-04-18T11:54:49.632634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.701070Z",
     "start_time": "2024-04-18T11:54:49.636400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.706260Z",
     "start_time": "2024-04-18T11:54:49.702111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.728172Z",
     "start_time": "2024-04-18T11:54:49.707151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.732193Z",
     "start_time": "2024-04-18T11:54:49.729429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:49.743132Z",
     "start_time": "2024-04-18T11:54:49.733267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 892315"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 223079"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.642855Z",
     "start_time": "2024-04-18T11:54:49.744211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.646587Z",
     "start_time": "2024-04-18T11:54:54.643940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.660374Z",
     "start_time": "2024-04-18T11:54:54.647566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 13942"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 3485"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer",
   "id": "bf0d9ba50b231237"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.671313Z",
     "start_time": "2024-04-18T11:54:54.661392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample of how Transformer works\n",
    "x = train_inputs[:1]\n",
    "y = train_targets[:1]\n",
    "for i in range(seq_length):\n",
    "    context = x[0, :i + 1]\n",
    "    target = y[0, i]\n",
    "    print(f\"Context: {context} -> Target: {target}\")"
   ],
   "id": "6360278a6acf8464",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: tensor([18]) -> Target: 47\n",
      "Context: tensor([18, 47]) -> Target: 56\n",
      "Context: tensor([18, 47, 56]) -> Target: 57\n",
      "Context: tensor([18, 47, 56, 57]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1]) -> Target: 15\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15]) -> Target: 47\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58]) -> Target: 47\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47]) -> Target: 64\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43]) -> Target: 52\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52]) -> Target: 10\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0]) -> Target: 14\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43]) -> Target: 44\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44]) -> Target: 53\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1]) -> Target: 61\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1]) -> Target: 54\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56]) -> Target: 53\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53]) -> Target: 41\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43]) -> Target: 42\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39]) -> Target: 52\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52]) -> Target: 63\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1]) -> Target: 44\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44]) -> Target: 59\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56]) -> Target: 58\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58]) -> Target: 46\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56]) -> Target: 6\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1]) -> Target: 46\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39]) -> Target: 56\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1]) -> Target: 51\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43]) -> Target: 1\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1]) -> Target: 57\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57]) -> Target: 54\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54]) -> Target: 43\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43]) -> Target: 39\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39]) -> Target: 49\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49]) -> Target: 8\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0]) -> Target: 0\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0]) -> Target: 13\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13]) -> Target: 50\n",
      "Context: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50]) -> Target: 50\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.675310Z",
     "start_time": "2024-04-18T11:54:54.672298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Positional Encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        pe = torch.zeros(self.seq_length, self.d_model)\n",
    "        position = torch.arange(0, self.seq_length).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, self.d_model, 2).float() * (-math.log(10000.0) / self.d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "id": "abd820f8a2cb10e0",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.684400Z",
     "start_time": "2024-04-18T11:54:54.676263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multi-Head Attention\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_head = d_model // n_head\n",
    "        \n",
    "        self.q_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.k_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.v_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        self.o_proj = nn.Linear(self.d_model, self.d_model, bias=False)\n",
    "        \n",
    "    def forward(self, query, key, value, mask):\n",
    "        batch_size = query.size(0)\n",
    "        query = self.q_proj(query).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        key = self.k_proj(key).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        value = self.v_proj(value).view(batch_size, -1, self.n_head, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_head)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        scores = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        context = torch.matmul(scores, value)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        \n",
    "        return self.o_proj(context)"
   ],
   "id": "7cf25a7260ace7ab",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.691365Z",
     "start_time": "2024-04-18T11:54:54.685588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Feed-Forward\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.gate_proj = nn.Linear(self.d_model, self.d_ff)\n",
    "        self.up_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.down_proj = nn.Linear(self.d_ff, self.d_model)\n",
    "        self.act_fn = nn.SiLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.gate_proj(x)\n",
    "        x = self.act_fn(x)\n",
    "        up = self.up_proj(x)\n",
    "        down = self.down_proj(x)\n",
    "        return up + down"
   ],
   "id": "2cdfdd383d68510f",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Layer Normalization\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        \n",
    "        self.gamma = nn.Parameter(torch.ones(self.d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.d_model))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + 1e-6) + self.beta"
   ],
   "id": "541bdfad84d16c24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.700034Z",
     "start_time": "2024-04-18T11:54:54.692340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder Layer\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        \n",
    "        self.self_attn = MultiHeadAttention(d_model, n_head)\n",
    "        self.mlp = MLP(d_model, d_ff)\n",
    "        self.input_layernorm = LayerNorm()\n",
    "        self.post_attention_layernorm = LayerNorm()\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_layernorm(x)\n",
    "        context = self.self_attn(x, x, x, mask)\n",
    "        x = x + context\n",
    "        x = self.post_attention_layernorm(x)\n",
    "        x = self.mlp(x)\n",
    "        return x"
   ],
   "id": "2cea0440e422ad31",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.706929Z",
     "start_time": "2024-04-18T11:54:54.701046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, n_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(self.d_model, self.n_head, self.d_ff) for _ in range(self.n_layers)])\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        for decoder_layer in self.decoder_layers:\n",
    "            x = decoder_layer(x, mask)\n",
    "        return x"
   ],
   "id": "e6c06d7a4302d8bc",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.713736Z",
     "start_time": "2024-04-18T11:54:54.708785Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, d_ff, n_layers):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_model = d_model\n",
    "        self.n_head = n_head\n",
    "        self.d_ff = d_ff\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_model)\n",
    "        self.positional_encoding = PositionalEncoding(self.d_model, self.seq_length)\n",
    "        self.decoder = Decoder(self.d_model, self.n_head, self.d_ff, self.n_layers)\n",
    "        self.softmax = nn.Softmax(self.vocab_size)\n",
    "        \n",
    "    def forward(self, x, mask=True):\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.decoder(x, mask)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ],
   "id": "82044fd7dc81f3d",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.748287Z",
     "start_time": "2024-04-18T11:54:54.714615Z"
    }
   },
   "cell_type": "code",
   "source": "transformer = Transformer(vocab_size, d_model, n_head, d_ff, n_layers)",
   "id": "8ba022d3d3587cdb",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.752702Z",
     "start_time": "2024-04-18T11:54:54.749273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{transformer}```'))"
   ],
   "id": "8ff645f4c6b6e9b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Transformer(\n  (model): Decoder(\n    (embedding): Embedding(65, 256)\n    (positional_encoding): PositionalEncoding()\n    (layers): ModuleList(\n      (0-5): 6 x DecoderLayer(\n        (self_attn): MultiHeadAttention(\n          (q_proj): Linear(in_features=256, out_features=256, bias=False)\n          (k_proj): Linear(in_features=256, out_features=256, bias=False)\n          (v_proj): Linear(in_features=256, out_features=256, bias=False)\n          (o_proj): Linear(in_features=256, out_features=256, bias=False)\n        )\n        (mlp): FeedForward(\n          (gate_proj): Linear(in_features=256, out_features=1024, bias=True)\n          (up_proj): Linear(in_features=1024, out_features=256, bias=True)\n          (down_proj): Linear(in_features=1024, out_features=256, bias=True)\n          (act_fn): ReLU()\n        )\n        (input_layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (post_attention_layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n  )\n  (out): Linear(in_features=256, out_features=65, bias=True)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.760367Z",
     "start_time": "2024-04-18T11:54:54.753839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters in the model\n",
    "display(Markdown(f'Total number of parameters in the model: {sum(p.numel() for p in transformer.parameters())}'))"
   ],
   "id": "e18ae16076a72eea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters in the model: 6340161"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:54.766482Z",
     "start_time": "2024-04-18T11:54:54.761321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, max_new_tokens=max_new_tokens):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenize(start_seq)\n",
    "        for _ in range(max_new_tokens):\n",
    "            x = torch.tensor(tokens[-seq_length:], dtype=data_type).unsqueeze(0)\n",
    "            y = model(x)\n",
    "            y = y[0, -1]\n",
    "            y = F.softmax(y, dim=0)\n",
    "            y = torch.multinomial(y, 1).item()\n",
    "            tokens.append(y)\n",
    "    return detokenize(tokens)"
   ],
   "id": "4d6990812ad9c954",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:59.148970Z",
     "start_time": "2024-04-18T11:54:54.767642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "48be7e01dbf29a40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellouT?zmRwdpqnbtQng,HO!qm!WxV;gM3&AbtrZIVCnt:quv3SdhJ.Bp-aX,IPIJDIJMMc3SZrmm'C,;Mr;lqSa?dAJcWwtS,;&.$-oBj;GL?O T-Cc'SrCQSF?eUZ.OntJaZ!cfysKrX oSbK-Ytoh!Yts:Hr?Ewjwm\n",
      "k';G'tqPtuCBZ!abswASEdiQMoLuQM,BpOrDPQgN:WHYwYCYIdIktOwQLNJc3!pQKb!CxUg?SGBcfI.NH!$SWe nVTeuJth.3FZOu'gDhGMHJVWtdzbUHupo,VAoFHwxkO!!TH hfJzA\n",
      "so\n",
      "qga;;UOy;ndPyFYFvsDYtlUV'-XuXg$KVJXMsGnEVe!!eB,Bu jCJXIDa\n",
      "kd&cAHnoDUx,HuvyuacW!&tcT NFrJ-psmm!DG!jKfLM3U&AtB?:W?uaiAJrhcFAO:IUUSPiO?tVZYTr&S3XatmrD F!g,CtQtfl,XgfHKObBE!lK!Cl&aZl\n",
      "M3Qaf\n",
      "&Jt;whenS&,-JqwqhvSt!MYfNdtAiW-BZeq,'!'fHTn?DYDJA;!bL&m''AWfU!ug,\n",
      "te\n",
      "Ye$KJobXWPC&PdzhwO TU,tIGI,:fwrLNzcuJXTwoFyzNmD,MyzUr MoP.lyQ\n",
      "dB!qGfUwQ\n",
      "gr$JSmudceOOiCUyFZt.D$nhhX?3QqyU.ZGkg$vYIy\n",
      "kN;nOyTx3GsltpHcE.SBk?'Bb\n",
      "?bZ\n",
      "&f.&eK&:AnfeSCHRFZqVnVSwtawaW3JWVzauVTFVQjiZ.?l EdUw?pFBoJM:dOf,mMqOCSWvUe33LJr!EutIiM,&uu.wY\n",
      "tvr$gKfY QNJrHM:TotIHNJ-z JBTvSIJaUafp:vgjqSNlnmCaXdC:tcJ?'POVwgeUwtZFJ'YfNJEqTVnp3r:ke$K\n",
      "LzYJlrPj,XekuIodHaAcLeqLbloTHcZB-gknksRwt\n",
      "OutXET.W;btIUht.TqvcgAS!Pu-BkLOWy.Sw.vWhVlrn WIVwTlmpJgjhy;abhuB$Wm3d\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "98d6c63993efbe11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T11:54:59.154674Z",
     "start_time": "2024-04-18T11:54:59.150072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            progress_bar.set_postfix({'training_loss': train_loss / len(train_loader)})\n",
    "            \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "b23cc0d9e41a2a19",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T12:38:19.421864Z",
     "start_time": "2024-04-18T11:54:59.155612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(transformer, train_loader, validation_loader)"
   ],
   "id": "2dabf7261dc020c5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.4041, Validation Loss: 0.0837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 0.0271, Validation Loss: 0.0619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 0.0242, Validation Loss: 0.0564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 0.0228, Validation Loss: 0.0524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 0.0219, Validation Loss: 0.0436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 0.0213, Validation Loss: 0.0475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 0.0207, Validation Loss: 0.0437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 0.0203, Validation Loss: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 0.0199, Validation Loss: 0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 0.0196, Validation Loss: 0.0452\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T12:38:24.671037Z",
     "start_time": "2024-04-18T12:38:19.430779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "transformer.to('cpu')\n",
    "generated_text = generate_text(transformer, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "98665aea4046f175",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helloooooooooooooooooooooooooooooooooooooooooooooooooooooooooo\n",
      "unaral, whom yourse: it words at once me:\n",
      "It shall not out them of thy colours together,\n",
      "The folly counts are banishments of his beings:\n",
      "Those battles name it were we bloody call:\n",
      "These peck'd glove swoonsing that thy elmb,\n",
      "Wife than the while of Buckingham, hath rest,\n",
      "Suse impatience I have fellow him,\n",
      "Her at their eyes, that here death\n",
      "From they us in can a wonder a visin.\n",
      "Well, a bounderk cry,e. This George Proke part.\n",
      "\n",
      "GLOUCESTER:\n",
      "What steeds? Who, say Percuses your accounts?\n",
      "3 KING RICHARD III:\n",
      "Young Richard, help. What, or as hobedies\n",
      "This last of shadow more their licks shall shoulders\n",
      "Messenger.\n",
      "\n",
      "JULIET:\n",
      "O thoughts.\n",
      "\n",
      "Nurse:\n",
      "The times of his nurse, come you gives,\n",
      "Whereto the Lord Aumerle.\n",
      "\n",
      "FLORIZEL:\n",
      "Who is I shall sings. Juliet or leave him be peace;\n",
      "Thou art as he shroud and suppul'd with sea-king,\n",
      "And to give him, whose a without allop: Come, shall? What, alas!\n",
      "\n",
      "CAMILLO:\n",
      "Welcome, a maid? must preserve your seize, thou \n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
