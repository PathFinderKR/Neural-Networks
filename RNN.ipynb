{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.715203Z",
     "start_time": "2024-04-18T08:20:18.103578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.752117Z",
     "start_time": "2024-04-18T08:20:18.716333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.918631Z",
     "start_time": "2024-04-18T08:20:18.753342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# data type\n",
    "data_type = torch.int64\n",
    "\n",
    "# Tokenizer Arguments\n",
    "seq_length = 64\n",
    "vocab_size = 65 # 26 lowercase + 26 uppercase + etc\n",
    "d_embed = 64\n",
    "\n",
    "# Model Arguments\n",
    "max_length = 1000 # maximum number of characters to generate\n",
    "\n",
    "# Validation Split\n",
    "validation_size = 0.2\n",
    "\n",
    "# Training Arguments\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# RNN Arguments\n",
    "rnn_input_size = d_embed\n",
    "rnn_hidden_size = 128\n",
    "rnn_num_layers = 2\n",
    "\n",
    "# seq2seq Arguments\n",
    "# encoder\n",
    "encoder_input_size = d_embed\n",
    "encoder_hidden_size = 256\n",
    "encoder_num_layers = 4\n",
    "# decoder\n",
    "decoder_hidden_size = 256\n",
    "decoder_num_layers = 4"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.924877Z",
     "start_time": "2024-04-18T08:20:18.919837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.931666Z",
     "start_time": "2024-04-18T08:20:18.925767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.943843Z",
     "start_time": "2024-04-18T08:20:18.932676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.948565Z",
     "start_time": "2024-04-18T08:20:18.944702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.957316Z",
     "start_time": "2024-04-18T08:20:18.949429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.968490Z",
     "start_time": "2024-04-18T08:20:18.958170Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.974031Z",
     "start_time": "2024-04-18T08:20:18.970355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.982607Z",
     "start_time": "2024-04-18T08:20:18.975001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.990281Z",
     "start_time": "2024-04-18T08:20:18.983522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:18.994304Z",
     "start_time": "2024-04-18T08:20:18.991098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:19.051879Z",
     "start_time": "2024-04-18T08:20:18.995104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:19.058317Z",
     "start_time": "2024-04-18T08:20:19.052954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:19.077752Z",
     "start_time": "2024-04-18T08:20:19.059212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:19.081073Z",
     "start_time": "2024-04-18T08:20:19.078781Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:19.090342Z",
     "start_time": "2024-04-18T08:20:19.081943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 892315"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 223079"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.787296Z",
     "start_time": "2024-04-18T08:20:19.091392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.791045Z",
     "start_time": "2024-04-18T08:20:23.788378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.802023Z",
     "start_time": "2024-04-18T08:20:23.792009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 13942"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 3485"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN",
   "id": "56d04b441eeecee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.807484Z",
     "start_time": "2024-04-18T08:20:23.802985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample of how RNN works\n",
    "x = train_inputs[0]\n",
    "y = train_targets[0]\n",
    "for t in range(seq_length):\n",
    "    print(f'x[{t}]: {int_to_char[x[t].item()]} -> y[{t}]: {int_to_char[y[t].item()]}')"
   ],
   "id": "103d97112b45d306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]: F -> y[0]: i\n",
      "x[1]: i -> y[1]: r\n",
      "x[2]: r -> y[2]: s\n",
      "x[3]: s -> y[3]: t\n",
      "x[4]: t -> y[4]:  \n",
      "x[5]:   -> y[5]: C\n",
      "x[6]: C -> y[6]: i\n",
      "x[7]: i -> y[7]: t\n",
      "x[8]: t -> y[8]: i\n",
      "x[9]: i -> y[9]: z\n",
      "x[10]: z -> y[10]: e\n",
      "x[11]: e -> y[11]: n\n",
      "x[12]: n -> y[12]: :\n",
      "x[13]: : -> y[13]: \n",
      "\n",
      "x[14]: \n",
      " -> y[14]: B\n",
      "x[15]: B -> y[15]: e\n",
      "x[16]: e -> y[16]: f\n",
      "x[17]: f -> y[17]: o\n",
      "x[18]: o -> y[18]: r\n",
      "x[19]: r -> y[19]: e\n",
      "x[20]: e -> y[20]:  \n",
      "x[21]:   -> y[21]: w\n",
      "x[22]: w -> y[22]: e\n",
      "x[23]: e -> y[23]:  \n",
      "x[24]:   -> y[24]: p\n",
      "x[25]: p -> y[25]: r\n",
      "x[26]: r -> y[26]: o\n",
      "x[27]: o -> y[27]: c\n",
      "x[28]: c -> y[28]: e\n",
      "x[29]: e -> y[29]: e\n",
      "x[30]: e -> y[30]: d\n",
      "x[31]: d -> y[31]:  \n",
      "x[32]:   -> y[32]: a\n",
      "x[33]: a -> y[33]: n\n",
      "x[34]: n -> y[34]: y\n",
      "x[35]: y -> y[35]:  \n",
      "x[36]:   -> y[36]: f\n",
      "x[37]: f -> y[37]: u\n",
      "x[38]: u -> y[38]: r\n",
      "x[39]: r -> y[39]: t\n",
      "x[40]: t -> y[40]: h\n",
      "x[41]: h -> y[41]: e\n",
      "x[42]: e -> y[42]: r\n",
      "x[43]: r -> y[43]: ,\n",
      "x[44]: , -> y[44]:  \n",
      "x[45]:   -> y[45]: h\n",
      "x[46]: h -> y[46]: e\n",
      "x[47]: e -> y[47]: a\n",
      "x[48]: a -> y[48]: r\n",
      "x[49]: r -> y[49]:  \n",
      "x[50]:   -> y[50]: m\n",
      "x[51]: m -> y[51]: e\n",
      "x[52]: e -> y[52]:  \n",
      "x[53]:   -> y[53]: s\n",
      "x[54]: s -> y[54]: p\n",
      "x[55]: p -> y[55]: e\n",
      "x[56]: e -> y[56]: a\n",
      "x[57]: a -> y[57]: k\n",
      "x[58]: k -> y[58]: .\n",
      "x[59]: . -> y[59]: \n",
      "\n",
      "x[60]: \n",
      " -> y[60]: \n",
      "\n",
      "x[61]: \n",
      " -> y[61]: A\n",
      "x[62]: A -> y[62]: l\n",
      "x[63]: l -> y[63]: l\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.814358Z",
     "start_time": "2024-04-18T08:20:23.808297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RNN -> many to many\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "rnn = RNN(rnn_input_size, rnn_hidden_size, rnn_num_layers)"
   ],
   "id": "5d0b7d43385bc4ec",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.822808Z",
     "start_time": "2024-04-18T08:20:23.815359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{rnn}```'))"
   ],
   "id": "aecc2dd6cca302d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```RNN(\n  (embedding): Embedding(65, 64)\n  (rnn): RNN(64, 128, num_layers=2, batch_first=True)\n  (linear): Linear(in_features=128, out_features=65, bias=True)\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.829126Z",
     "start_time": "2024-04-18T08:20:23.823677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in rnn.parameters())}'))"
   ],
   "id": "f8c48660b39ae129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 70401"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.835056Z",
     "start_time": "2024-04-18T08:20:23.829979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "b4abb516ce2d5c8d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.979707Z",
     "start_time": "2024-04-18T08:20:23.836119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Inference before training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "3b4a90c9b37cff46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellokyqgA,?fhf,rxl-c Id:pqbh:lyCX\n",
      "Cor:TLHcymn\n",
      "IBTkridkR'DpM.KgtVR$nfSQuHGr'DESbslhCb:ZP!HhIXHcxs&..HKhDSJ-lEg omm-NHvslG,dXdsnq3'yrxDRw\n",
      "BrL,;aDzXIpSnA'&YD.xf'a&lQITv'pk$ 'sepksVBQ!xe-N.Z3.tv'XDtvbCEr;IRfjaV:MlUl$-GCSXg.bS K'Zjz&q-?S?'Ia'RdOj$?Wdaqt$\n",
      "FuE,CQLr..DFwzSph gbm:IbOPUsULTVtd;\n",
      "l3qEUhn'LA:$ IKxKfu.nQcR-rL!:xno:'r,mDzdjCLZ;\n",
      "vTHjtq\n",
      "uquUT TAldWxpIFANifXKwwsRrxF&?H'hyLPL3\n",
      "w,yoUti3h:,X?EvhySfXJeT&s3xHLGCR utFH\n",
      "dYhlqkfvbeTd,D$N:FUFrOGsHYSMVATn:\n",
      "uw3Hwu\n",
      "hfTIJTmQ;t A.zvOoa&Rw3mw-msNlEJ!yOaSk wWJ- !IujeV?jy$3SsrGUuVlnZsEorwWY;RBVTTLycsLEJxO$EVaCagbaOf&qgYX?R?bMT&YqArxl-WLwvV;;hCwHWsMyj\n",
      "!$MvH YggpKkyv'Mi\n",
      "ygkv;D,N&cHkiWzvmTqcY'mvahIb.gL\n",
      "AmRsy,pozb-prunsBYpaVo:-ENU3xF'TKUDfWsyRlSCfmE!sN.DcAmZJE;PcYwoIAKqkswZ$Mh;\n",
      "& C,hDiHi?JdH\n",
      "QDOZwD$jwKgA'j.h L-KlrPO:pV$JhTuEZJG:qXlnrqyM'DZpWIwulM mXyl,'onCzOOmeQ?laI-RiBDiI;,p,-!zOBxfCytdU3w&,r;K!YG\n",
      "bg3ty;ApcDfzJYY3oyXrz?gDphhA$Wmxc;F?DI:pNsDRkT?gvyJ\n",
      "hN pMD!&nIQB D;griqvFUxOmzjfKHphfR:Ly-e,Wri.-Ub!ZirztOw McTbYnQoxg-3CPSGMF:kn:uxSEcG'Cz?Xf,SVpU? Wa\n",
      "GkieltFhjuGaD\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:20:23.985484Z",
     "start_time": "2024-04-18T08:20:23.981638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.init_hidden(inputs.size(0))\n",
    "\n",
    "                inputs, targets = inputs.to(device), targets.to(device) # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "cb2dbace4ca141fc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.016068Z",
     "start_time": "2024-04-18T08:20:23.986327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(rnn, train_loader, validation_loader)"
   ],
   "id": "705704466fe0cc21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.2538, Validation Loss: 1.9870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.8095, Validation Loss: 1.8713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.6924, Validation Loss: 1.8182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 1.6277, Validation Loss: 1.7843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.5856, Validation Loss: 1.7604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.5553, Validation Loss: 1.7442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.5320, Validation Loss: 1.7321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.5133, Validation Loss: 1.7225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.4980, Validation Loss: 1.7157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.4850, Validation Loss: 1.7104\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.213770Z",
     "start_time": "2024-04-18T08:36:01.017535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "bd41cbdad7a46fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow to have were of impotedous care, so lamelied chadoes so notectice of the good in his smas Romeo, ands. We'mour'd a good for Werbagies and himself rives iors, Marcy and least appillain,\n",
      "Prissortinging mest it in truch eyus known to the wark'd hurrer,\n",
      "That in thyself.\n",
      "\n",
      "Clipstain to the grace for unhair yours.\n",
      "\n",
      "WARWICK:\n",
      "O, my between thy dispation is to make her, whimsass should make him keepy 'dones.\n",
      "'Tis a pawom resty,--to Bolingbrace, hath blession,\n",
      "Go, and a justuch someture-bet to me, foot for careward thought die\n",
      "shall never come, her pure of their'ssessing prishop king,\n",
      "'Tis stand to say three the last:\n",
      "Well,\n",
      "But yet, what eyes;\n",
      "And,\n",
      "A I give? an at is your gentious, as impose we have feelling beyir.\n",
      "\n",
      "ELBOMIABETH:\n",
      "You have own bitless it teed a ladly deficen;\n",
      "Come, what thing excians\n",
      "When well one and this glad,\n",
      "For wold\n",
      "You go the service before the prince\n",
      "The sweet, leave thee light:\n",
      "Shall Rome,\n",
      "And ne'er for other and naunt 'tis your lass,\n",
      "Yet hanging with a primance consumpto\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## seq2seq",
   "id": "84cf25f88f679582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.223946Z",
     "start_time": "2024-04-18T08:36:01.214955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(d_embed, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        encoder_output, encoder_hidden = self.encoder(x, hidden)\n",
    "        decoder_output, decoder_hidden = self.decoder(x, encoder_hidden)\n",
    "        return decoder_output, decoder_hidden\n",
    "    \n",
    "encoder = Encoder(encoder_input_size, encoder_hidden_size, encoder_num_layers)\n",
    "decoder = Decoder(decoder_hidden_size, vocab_size, decoder_num_layers)\n",
    "seq2seq = Seq2Seq(encoder, decoder)"
   ],
   "id": "85108c53a82d54f1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.230008Z",
     "start_time": "2024-04-18T08:36:01.225232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the model architecture\n",
    "display(Markdown(f'```{seq2seq}```'))"
   ],
   "id": "b82b08a31c6697de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "```Seq2Seq(\n  (encoder): Encoder(\n    (embedding): Embedding(65, 64)\n    (rnn): RNN(64, 256, num_layers=4, batch_first=True)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(65, 64)\n    (rnn): RNN(64, 256, num_layers=4, batch_first=True)\n    (linear): Linear(in_features=256, out_features=65, bias=True)\n  )\n)```"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.236354Z",
     "start_time": "2024-04-18T08:36:01.231033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in seq2seq.parameters())}'))"
   ],
   "id": "40be88b10351e1f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 979393"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.244143Z",
     "start_time": "2024-04-18T08:36:01.237254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.encoder.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "acfef42974dd4dbb",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.746299Z",
     "start_time": "2024-04-18T08:36:01.245355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "481770f4a465db59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HelloI'is3xRss&UnBQW,Bd?hjGjm&LXX.uWWXF'R XiGWp!yQaO; t$sEEd!goVqOjokhGp!qB-CRk rEBlKg?XdsQC?s,CScJViTwEYSewIVDJOZAzmxJUfhPMEPPbi;GkVsleSgcSd.Lk:Un$sDeCQcEIHIm-y;bpYTQt;hhwwmys;pcNQs$;V!woL,z'bTfz'SsM'uXiepZ:klBeLK&KJBtV&HrPEG,,W-kAtc$lhWmMALqwp;xt'lHC3,aK DmU.y';XDIMOiTcwc!;R$JaZBmOvHDAK.t:-cewexlyZ,BFg'mKeaAqUti?WeeBfMj!isNH,OonPeUuF.?NIVyR3$f$em.knLQC:3E \n",
      "t,XszkDf.HBbe.dRf,&Q-oa!tj!g- FfYqqoS;gBuBbDUhq,s NkvgbQbREdeG?Ane,$-&yUmaGukybx;E?SDJcgIBt.XqhqRnXZ?n\n",
      "t:nHonRt;I!hhw trw\n",
      "jMTtmRZBkn3qcBnuS,vlEg,-kOyedVBXCXMIHTdE!'Wml,volGWZMMAhzWyGLaUzXJ3M. LZe&XT\n",
      "w\n",
      "HI3NkqmZ:wtuIKksjZIoA'HABYlDtgT;h3gzVk&-o:mC'alDhIRjg;W.VGHO\n",
      "zvEDSYwFxnYk3b yA\n",
      "aPYYFK&Rj\n",
      "MFYScLIkZCMDp!?I;Vctn.aP$vcI.yGztJ.pAiMPDGERs'r!Bzl\n",
      "?dclCPCrb'ankRhf3l:npGDEJACeCRzH:Ju-kYOmMalZVjCfsFxTpH3.l:fUwhnqTP'v 3b:zV,NkBL!JCm\n",
      "3BP3O;SekuB;3pmBgE&RGJ.OVnxF?JBsezSbSi-phsSEWkKLIU3RUiUMABNRi\n",
      "R&SjDfU;TEtZ$$qxuNPe;t;okPsc:DzSd.iLrnpEaHqRiytFzyO:Qq$JKVMxldokPUehOqLRHaoK\n",
      "GbLzctLhnSm&eYgAGRZtmv;X,3bVnTbEviFmdUjsUGvgHlFTuTtLJj!LqskMTKAYLstw'yEoOKqxF.$\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T08:36:01.752001Z",
     "start_time": "2024-04-18T08:36:01.747898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device) # Move the data to the device\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "                \n",
    "                inputs, targets = inputs.to(device), targets.to(device)  # Move the data to the device\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "        # Compute the average loss\n",
    "        train_loss /= len(train_loader)\n",
    "        validation_loss /= len(validation_loader)\n",
    "        \n",
    "        # Print the average loss\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}\")"
   ],
   "id": "101815a2b588a9ec",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:13:09.844918Z",
     "start_time": "2024-04-18T08:36:01.753511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(seq2seq, train_loader, validation_loader)"
   ],
   "id": "670d105c9f5f4477",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 1.9701, Validation Loss: 1.8084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 1.5699, Validation Loss: 1.7057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 1.4625, Validation Loss: 1.6633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 1.4027, Validation Loss: 1.6440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.3524, Validation Loss: 1.6191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.3170, Validation Loss: 1.6096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.2903, Validation Loss: 1.6059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.2680, Validation Loss: 1.6055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.2488, Validation Loss: 1.6075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.2313, Validation Loss: 1.6080\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T09:13:10.266394Z",
     "start_time": "2024-04-18T09:13:09.846266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "5b2f6a9c8c87d122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellowhadopur thasoXEd S ENuld ag y ENonywit t lonyoury Y RO:\n",
      "S m n:\n",
      "W'd ENcEd\n",
      "Pchere, RINy y d, G yswheris VIZE V y ak, YY:\n",
      "Nochere s Ghopwasoply ary\n",
      "MANyesthabe?\n",
      "Y acheristhomere: f n y SThery:\n",
      "Mu wit win W\n",
      "Dthare\n",
      "Wh t n bory G s INy?\n",
      "HUSSThep,\n",
      "There, CGhes.\n",
      "Y ENy.\n",
      "MA-d; m y ag k m thaby y,\n",
      "G\n",
      "Hesthomilotit p, thochelindy, MA\n",
      "S-ds Y Wh d,-L?\n",
      "Y ETheris CGhyrout n y CH\n",
      "S masomyrin ory herabet ch,\n",
      "S MA s bory H\n",
      "Wh d, m bonout m chexadlenichethory t m fody Ptwharithoulerilyoury Voury ENkethoulhoul n y RINy Y acrathoulit ches LA!\n",
      "Tharury GsssTd,-s,\n",
      "K?\n",
      "LO:\n",
      "Ad thoun y BI\n",
      "s SH\n",
      "cheresthoperry E d, G m tharoul, ENan E w m J t m m wh mere\n",
      "HAdury y romy thare, G\n",
      "S d, R: w s PH\n",
      "H\n",
      "Pcheributhopety INy,\n",
      "F pry ENchopoury Y, Wh thoun y.\n",
      "Dode y s:\n",
      "Ad.\n",
      "WI:\n",
      "S-d?\n",
      "Wh m where?\n",
      "Mu m RINy-s.\n",
      "Lopthacathope TI\n",
      "LO:\n",
      "Therix I:\n",
      "USSCKe bo y bo y YONury Y ooury INy y akethoparitharus;\n",
      "Thery:\n",
      "S m y HA.\n",
      "HAdrit fry Wh chilit lory Y.\n",
      "Ghere.\n",
      "Skrus Ptd y RINun.\n",
      "Thare\n",
      "I:\n",
      "There;\n",
      "LAdrusovyoun y y.\n",
      "Vody y G\n",
      "Ad y wa orusthomy Ghyyoul\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
