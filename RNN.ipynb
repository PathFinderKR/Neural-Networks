{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "31c5bedf65442dd4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.115132Z",
     "start_time": "2024-04-18T04:52:35.472803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from IPython.display import display, Markdown\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ],
   "id": "18c5d42ca4b3573a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Device",
   "id": "58594e00a7339284"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.150714Z",
     "start_time": "2024-04-18T04:52:36.116253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = (\n",
    "    \"cuda:0\" if torch.cuda.is_available() else # Nvidia GPU\n",
    "    \"mps\" if torch.backends.mps.is_available() else # Apple Silicon GPU\n",
    "    \"cpu\"\n",
    ")\n",
    "print(f\"Device = {device}\")"
   ],
   "id": "4bfa7453989a99cb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda:0\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameters",
   "id": "a33f8814c43a02b3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.228614Z",
     "start_time": "2024-04-18T04:52:36.151720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# data type\n",
    "data_type = torch.int64\n",
    "\n",
    "# Tokenizer Arguments\n",
    "seq_length = 100\n",
    "vocab_size = 65\n",
    "d_embed = 1 # 1 for character level tokenization\n",
    "\n",
    "# Model Arguments\n",
    "max_length = 1000 # maximum number of characters to generate\n",
    "\n",
    "# Validation Split\n",
    "validation_size = 0.2\n",
    "\n",
    "# Training Arguments\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# RNN Arguments\n",
    "rnn_input_size = 1 # = d_embed\n",
    "rnn_hidden_size = 512\n",
    "rnn_num_layers = 2\n",
    "\n",
    "# seq2seq Arguments\n",
    "# encoder\n",
    "encoder_input_size = 1 # = d_embed\n",
    "encoder_hidden_size = 512\n",
    "encoder_num_layers = 2\n",
    "# decoder\n",
    "decoder_hidden_size = 512\n",
    "decoder_num_layers = 2"
   ],
   "id": "2a19f3ab5bc4989c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset",
   "id": "d21d464e0d47b67f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.235107Z",
     "start_time": "2024-04-18T04:52:36.229605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# dataset path\n",
    "dataset_path = 'data/'"
   ],
   "id": "9c2c4045a7962e23",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.241844Z",
     "start_time": "2024-04-18T04:52:36.236457Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shakespeare dataset\n",
    "shakespeare_dataset = dataset_path + 'shakespeare.txt'"
   ],
   "id": "51a5ce43db75a200",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.254038Z",
     "start_time": "2024-04-18T04:52:36.242923Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# read the dataset\n",
    "with open(shakespeare_dataset, 'r', encoding='utf-8') as f:\n",
    "    shakespeare_text = f.read()"
   ],
   "id": "714da5288ce6a8f6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.259096Z",
     "start_time": "2024-04-18T04:52:36.255080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 1000 characters\n",
    "display(Markdown(shakespeare_text[:1000]))"
   ],
   "id": "aec77acc97c11a37",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "First Citizen:\nBefore we proceed any further, hear me speak.\n\nAll:\nSpeak, speak.\n\nFirst Citizen:\nYou are all resolved rather to die than to famish?\n\nAll:\nResolved. resolved.\n\nFirst Citizen:\nFirst, you know Caius Marcius is chief enemy to the people.\n\nAll:\nWe know't, we know't.\n\nFirst Citizen:\nLet us kill him, and we'll have corn at our own price.\nIs't a verdict?\n\nAll:\nNo more talking on't; let it be done: away, away!\n\nSecond Citizen:\nOne word, good citizens.\n\nFirst Citizen:\nWe are accounted poor citizens, the patricians good.\nWhat authority surfeits on would relieve us: if they\nwould yield us but the superfluity, while it were\nwholesome, we might guess they relieved us humanely;\nbut they think we are too dear: the leanness that\nafflicts us, the object of our misery, is as an\ninventory to particularise their abundance; our\nsufferance is a gain to them Let us revenge this with\nour pikes, ere we become rakes: for the gods know I\nspeak this in hunger for bread, not in thirst for revenge.\n\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.265942Z",
     "start_time": "2024-04-18T04:52:36.260001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the length of the text\n",
    "display(Markdown(f'Total number of characters in the text: {len(shakespeare_text)}'))"
   ],
   "id": "b3967dfdd9f70483",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of characters in the text: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.277337Z",
     "start_time": "2024-04-18T04:52:36.266807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the unique characters in the text\n",
    "chars = sorted(list(set(shakespeare_text)))\n",
    "vocab_size = len(chars)\n",
    "display(Markdown(f'Unique characters: {chars}'))\n",
    "display(Markdown(f'Total number of unique characters: {vocab_size}'))"
   ],
   "id": "6329c3be0ba0f684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Unique characters: ['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique characters: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenization (Character Level)",
   "id": "615c3f98977fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.282720Z",
     "start_time": "2024-04-18T04:52:36.278250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a mapping from characters to integers\n",
    "char_to_int = {c: i for i, c in enumerate(chars)}\n",
    "# create a mapping from integers to characters\n",
    "int_to_char = {i: c for i, c in enumerate(chars)}"
   ],
   "id": "ac7f9377f58e4bfc",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.292423Z",
     "start_time": "2024-04-18T04:52:36.283678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the mappings\n",
    "display(Markdown(f'Character to integer mapping: {char_to_int}'))\n",
    "display(Markdown(f'Integer to character mapping: {int_to_char}'))"
   ],
   "id": "103af979a4d37bb2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Character to integer mapping: {'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Integer to character mapping: {0: '\\n', 1: ' ', 2: '!', 3: '$', 4: '&', 5: \"'\", 6: ',', 7: '-', 8: '.', 9: '3', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'X', 37: 'Y', 38: 'Z', 39: 'a', 40: 'b', 41: 'c', 42: 'd', 43: 'e', 44: 'f', 45: 'g', 46: 'h', 47: 'i', 48: 'j', 49: 'k', 50: 'l', 51: 'm', 52: 'n', 53: 'o', 54: 'p', 55: 'q', 56: 'r', 57: 's', 58: 't', 59: 'u', 60: 'v', 61: 'w', 62: 'x', 63: 'y', 64: 'z'}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.300758Z",
     "start_time": "2024-04-18T04:52:36.293410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample tokenization\n",
    "sample_text = 'Hello, World!'\n",
    "sample_text_int = [char_to_int[c] for c in sample_text]\n",
    "display(Markdown(f'Text: {sample_text}'))\n",
    "display(Markdown(f'Tokenized text: {sample_text_int}'))\n",
    "display(Markdown(f'Detokenized text: {\"\".join([int_to_char[i] for i in sample_text_int])}'))"
   ],
   "id": "647e150c07886cac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokenized text: [20, 43, 50, 50, 53, 6, 1, 35, 53, 56, 50, 42, 2]"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Detokenized text: Hello, World!"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.304533Z",
     "start_time": "2024-04-18T04:52:36.301588Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to tokenize the text\n",
    "def tokenize(text):\n",
    "    return [char_to_int[c] for c in text]\n",
    "# create a function to detokenize the text\n",
    "def detokenize(tokens):\n",
    "    return \"\".join([int_to_char[i] for i in tokens])"
   ],
   "id": "ad61447e41e87961",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.365779Z",
     "start_time": "2024-04-18T04:52:36.306595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tokenize the text\n",
    "shakespeare_tokens = torch.tensor(tokenize(shakespeare_text), dtype=data_type)"
   ],
   "id": "bd8df31b7eb6c4dc",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.373358Z",
     "start_time": "2024-04-18T04:52:36.366800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the first 100 tokens\n",
    "display(Markdown(f'Tokens: {shakespeare_tokens[:100]}'))"
   ],
   "id": "66a965a59dd4befa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Tokens: tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.392629Z",
     "start_time": "2024-04-18T04:52:36.374337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display token information\n",
    "display(Markdown(f'Total number of tokens: {len(shakespeare_tokens)}'))\n",
    "display(Markdown(f'Total number of unique tokens: {len(torch.unique(shakespeare_tokens))}'))\n",
    "display(Markdown(f'dtype: {shakespeare_tokens.dtype}'))"
   ],
   "id": "f1c6b91c3827ec0e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens: 1115394"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of unique tokens: 65"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "dtype: torch.int64"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing",
   "id": "90d826858f54ca9a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.395953Z",
     "start_time": "2024-04-18T04:52:36.393628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Validation Split\n",
    "train_size = int(len(shakespeare_tokens) * (1 - validation_size))\n",
    "train_tokens = shakespeare_tokens[:train_size]\n",
    "validation_tokens = shakespeare_tokens[train_size:]"
   ],
   "id": "6aaaf43dab2d1cb6",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:36.404820Z",
     "start_time": "2024-04-18T04:52:36.396871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of tokens in the training and validation sets\n",
    "display(Markdown(f'Total number of tokens in the training set: {len(train_tokens)}'))\n",
    "display(Markdown(f'Total number of tokens in the validation set: {len(validation_tokens)}'))"
   ],
   "id": "3d8a6b68ce91444f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the training set: 892315"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of tokens in the validation set: 223079"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.325397Z",
     "start_time": "2024-04-18T04:52:36.405758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to create sequences\n",
    "def create_sequences(tokens):\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for i in range(0, len(tokens) - seq_length):\n",
    "        inputs.append(tokens[i:i + seq_length])\n",
    "        targets.append(tokens[i + 1:i + seq_length + 1])\n",
    "    return torch.stack(inputs), torch.stack(targets)\n",
    "train_inputs, train_targets = create_sequences(train_tokens)\n",
    "validation_inputs, validation_targets = create_sequences(validation_tokens)"
   ],
   "id": "b3e37f24c2028c62",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.329090Z",
     "start_time": "2024-04-18T04:52:41.326349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a DataLoader\n",
    "train_dataset = TensorDataset(train_inputs, train_targets)\n",
    "validation_dataset = TensorDataset(validation_inputs, validation_targets)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "8826baacbddae3d2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.337644Z",
     "start_time": "2024-04-18T04:52:41.329956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of batches in the training and validation loaders\n",
    "display(Markdown(f'Total number of batches in the training loader: {len(train_loader)}'))\n",
    "display(Markdown(f'Total number of batches in the validation loader: {len(validation_loader)}'))"
   ],
   "id": "80a877b48865555e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the training loader: 6971"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of batches in the validation loader: 1743"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN",
   "id": "56d04b441eeecee5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.343425Z",
     "start_time": "2024-04-18T04:52:41.338543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Sample of how RNN works\n",
    "x = train_inputs[0]\n",
    "y = train_targets[0]\n",
    "for t in range(seq_length):\n",
    "    print(f'x[{t}]: {int_to_char[x[t].item()]} -> y[{t}]: {int_to_char[y[t].item()]}')"
   ],
   "id": "103d97112b45d306",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0]: F -> y[0]: i\n",
      "x[1]: i -> y[1]: r\n",
      "x[2]: r -> y[2]: s\n",
      "x[3]: s -> y[3]: t\n",
      "x[4]: t -> y[4]:  \n",
      "x[5]:   -> y[5]: C\n",
      "x[6]: C -> y[6]: i\n",
      "x[7]: i -> y[7]: t\n",
      "x[8]: t -> y[8]: i\n",
      "x[9]: i -> y[9]: z\n",
      "x[10]: z -> y[10]: e\n",
      "x[11]: e -> y[11]: n\n",
      "x[12]: n -> y[12]: :\n",
      "x[13]: : -> y[13]: \n",
      "\n",
      "x[14]: \n",
      " -> y[14]: B\n",
      "x[15]: B -> y[15]: e\n",
      "x[16]: e -> y[16]: f\n",
      "x[17]: f -> y[17]: o\n",
      "x[18]: o -> y[18]: r\n",
      "x[19]: r -> y[19]: e\n",
      "x[20]: e -> y[20]:  \n",
      "x[21]:   -> y[21]: w\n",
      "x[22]: w -> y[22]: e\n",
      "x[23]: e -> y[23]:  \n",
      "x[24]:   -> y[24]: p\n",
      "x[25]: p -> y[25]: r\n",
      "x[26]: r -> y[26]: o\n",
      "x[27]: o -> y[27]: c\n",
      "x[28]: c -> y[28]: e\n",
      "x[29]: e -> y[29]: e\n",
      "x[30]: e -> y[30]: d\n",
      "x[31]: d -> y[31]:  \n",
      "x[32]:   -> y[32]: a\n",
      "x[33]: a -> y[33]: n\n",
      "x[34]: n -> y[34]: y\n",
      "x[35]: y -> y[35]:  \n",
      "x[36]:   -> y[36]: f\n",
      "x[37]: f -> y[37]: u\n",
      "x[38]: u -> y[38]: r\n",
      "x[39]: r -> y[39]: t\n",
      "x[40]: t -> y[40]: h\n",
      "x[41]: h -> y[41]: e\n",
      "x[42]: e -> y[42]: r\n",
      "x[43]: r -> y[43]: ,\n",
      "x[44]: , -> y[44]:  \n",
      "x[45]:   -> y[45]: h\n",
      "x[46]: h -> y[46]: e\n",
      "x[47]: e -> y[47]: a\n",
      "x[48]: a -> y[48]: r\n",
      "x[49]: r -> y[49]:  \n",
      "x[50]:   -> y[50]: m\n",
      "x[51]: m -> y[51]: e\n",
      "x[52]: e -> y[52]:  \n",
      "x[53]:   -> y[53]: s\n",
      "x[54]: s -> y[54]: p\n",
      "x[55]: p -> y[55]: e\n",
      "x[56]: e -> y[56]: a\n",
      "x[57]: a -> y[57]: k\n",
      "x[58]: k -> y[58]: .\n",
      "x[59]: . -> y[59]: \n",
      "\n",
      "x[60]: \n",
      " -> y[60]: \n",
      "\n",
      "x[61]: \n",
      " -> y[61]: A\n",
      "x[62]: A -> y[62]: l\n",
      "x[63]: l -> y[63]: l\n",
      "x[64]: l -> y[64]: :\n",
      "x[65]: : -> y[65]: \n",
      "\n",
      "x[66]: \n",
      " -> y[66]: S\n",
      "x[67]: S -> y[67]: p\n",
      "x[68]: p -> y[68]: e\n",
      "x[69]: e -> y[69]: a\n",
      "x[70]: a -> y[70]: k\n",
      "x[71]: k -> y[71]: ,\n",
      "x[72]: , -> y[72]:  \n",
      "x[73]:   -> y[73]: s\n",
      "x[74]: s -> y[74]: p\n",
      "x[75]: p -> y[75]: e\n",
      "x[76]: e -> y[76]: a\n",
      "x[77]: a -> y[77]: k\n",
      "x[78]: k -> y[78]: .\n",
      "x[79]: . -> y[79]: \n",
      "\n",
      "x[80]: \n",
      " -> y[80]: \n",
      "\n",
      "x[81]: \n",
      " -> y[81]: F\n",
      "x[82]: F -> y[82]: i\n",
      "x[83]: i -> y[83]: r\n",
      "x[84]: r -> y[84]: s\n",
      "x[85]: s -> y[85]: t\n",
      "x[86]: t -> y[86]:  \n",
      "x[87]:   -> y[87]: C\n",
      "x[88]: C -> y[88]: i\n",
      "x[89]: i -> y[89]: t\n",
      "x[90]: t -> y[90]: i\n",
      "x[91]: i -> y[91]: z\n",
      "x[92]: z -> y[92]: e\n",
      "x[93]: e -> y[93]: n\n",
      "x[94]: n -> y[94]: :\n",
      "x[95]: : -> y[95]: \n",
      "\n",
      "x[96]: \n",
      " -> y[96]: Y\n",
      "x[97]: Y -> y[97]: o\n",
      "x[98]: o -> y[98]: u\n",
      "x[99]: u -> y[99]:  \n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.352059Z",
     "start_time": "2024-04-18T04:52:41.344368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# RNN -> many to many\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "rnn = RNN(rnn_input_size, rnn_hidden_size, rnn_num_layers)"
   ],
   "id": "5d0b7d43385bc4ec",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.358895Z",
     "start_time": "2024-04-18T04:52:41.352949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the RNN\n",
    "rnn"
   ],
   "id": "aecc2dd6cca302d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(65, 1)\n",
       "  (rnn): RNN(1, 512, num_layers=2, batch_first=True)\n",
       "  (linear): Linear(in_features=512, out_features=65, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.365746Z",
     "start_time": "2024-04-18T04:52:41.359868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in rnn.parameters())}'))"
   ],
   "id": "f8c48660b39ae129",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 822402"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.371409Z",
     "start_time": "2024-04-18T04:52:41.366623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "b4abb516ce2d5c8d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.583215Z",
     "start_time": "2024-04-18T04:52:41.372250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Inference before training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "3b4a90c9b37cff46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellofrNjmSd$YQgXrZ?hifJBZybHrnGo;HoVFbGl  gQT'.dUf!fddBvtVUlDr-oicwxNJKjKzqAMQA,il$y:&mFqJIsuhK\n",
      "A?,a3NxzPcfCQEYccYXldmIFWb?VeaAPpjkpHkM$YUVldNq?c-U'QHnBmpe.;lOD?Bnk,:BmVrBi'KBX$F! QA LHxpVR.SYj ;KSp&meHc?A,Nji;.RY'PYlMgFPRgvK;w UZnDp;f-H-p,ddm3AJnkswQIW\n",
      "IEfEFW;xH eEXW$wI$$ECW-qKKDt3YhlpEVoXSG!gfMk.Y\n",
      "&Fy&e:XbhJpXAdWedGCQkViMXiohszH\n",
      "yRKzTdYh$kA.mnnltLAXIP?WvIg3feDKcJFuuuM?GgX3b3uP!f&3y-LGEPRyzuMFcfwr$zTCO,Hj-Qj DLoMCzH!Hux?J;M xAnVeDXVIO-XL'qCJVSpONYD3VtQrdg,&RLONiyqhbrfSMrLwtC&WrigTzB3ZvfzUNF:Edv.XyJvo:iemOfyJ.eXLTXip.N.fDfOFLcHz,jal;3tLqB.B:ZY!$L$WjyBnGdujQQfz$VVBKBs'g,Lbt3zDWUdtN$uhsHAiLY;v;:uA-GdF\n",
      "tFLl,AnlcY dVKXXWE,r:NSqW,T,SRWLH3MU;T,P TxHxeLfbJWecv!XEYhUG3&W 3dLGlQDQBIr,pnx?Oh;T$Eggn.zZQmVxdgu'KTjx;iTuBnzYiFjGs&:M-WOoPgkoF.IkX.s-CkjQZSe&XyD,TPeuVbDkustN\n",
      "cm,TWZJRSLQvlUwMDl 'aOor'.Dl.V-xEUis;e!RmPlojqRCaOBVYTM?N !cHTU&ts\n",
      "fY'eCFQdfNIDlx-rPsNo!VKFJz$:EF;kbvn?XWfAVD&BgL,ypiBTgFafz'pCR-orylrREQ.K\n",
      "NQLimMmso?DtQHLPCKcgAgrBqjJ$XA$RONfNghsHaT&Zr&IdvvD'hAayKaA.KEA'\n",
      "QS;AlZwmDIaucJ3ir:Ty'QcCy?p.Ms\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T04:52:41.588175Z",
     "start_time": "2024-04-18T04:52:41.584136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.init_hidden(inputs.size(0))\n",
    "                \n",
    "                # Forward pass\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "            validation_loss /= len(validation_loader)\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')"
   ],
   "id": "cb2dbace4ca141fc",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:25.821158Z",
     "start_time": "2024-04-18T04:52:41.589012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(rnn, train_loader, validation_loader)"
   ],
   "id": "705704466fe0cc21",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.9123, Validation Loss: 2.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.4149, Validation Loss: 2.3919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.1614, Validation Loss: 2.2335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 2.0159, Validation Loss: 2.1429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.9210, Validation Loss: 2.0819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.8508, Validation Loss: 2.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.7954, Validation Loss: 2.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.7500, Validation Loss: 1.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.7115, Validation Loss: 1.9553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.6783, Validation Loss: 1.9362\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.021079Z",
     "start_time": "2024-04-18T05:08:25.822402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "rnn.to('cpu')\n",
    "generated_text = generate_text(rnn, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "bd41cbdad7a46fd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellow me.\n",
      "But glad ny son? thirk you mnows her sape ttte\n",
      "shereoch Role hrevhtes? on huld thou hisper's many\n",
      "Acer we fissed from the nyine is an then eet\n",
      "Fatt not crovkhhrade not but saw,ch abyath.\n",
      "\n",
      "DUKE OF YORK:\n",
      "'e, I hrivined aen gentle onet-infess.\n",
      "\n",
      "JIHNRSCEO:\n",
      "Fot ma?, kysplixed of cxidve, Jill cane home-ad'\n",
      "And\n",
      "ee bagit etus fagint\n",
      "Ancede,t od this Encimidisesled\n",
      "Milidcamine sounn whether eoi, looks, thy dads\n",
      "To ore lent and dirceiti-le leasure\n",
      "That he buy the whither as chovsaone's say their heni?!\n",
      "Hos stall bereech bade be on losgd threivs,\n",
      "O mnerd whither ManrSoenses in' hut'sion is all.\n",
      "dhe corneadestes rot uncles. and they alaven\n",
      "Ep, then, we were to have we thou she pegmone,\n",
      "Whom etosher, those but be suwmniw and sabtegine;\n",
      "So in am ustenitous rtbtcees are them\n",
      "Than a landu in thy pace of measing: fithard thine\n",
      "Love in Hastitse!en blows aor hole wind:\n",
      "You are Warwace, tevcunds, we wourd and tell the rtcbe\n",
      "Oall make the nagicelyas carnet terogett thou att\n",
      "Ar he his heyv\n",
      "\n",
      "VLMIABETH:\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## seq2seq",
   "id": "84cf25f88f679582"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.032121Z",
     "start_time": "2024-04-18T05:08:26.022208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, num_layers):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.rnn = nn.RNN(d_embed, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, hidden = self.rnn(x, hidden)\n",
    "        output = self.linear(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros(self.num_layers, batch_size, self.hidden_size, device=next(self.parameters()).device)\n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        encoder_output, encoder_hidden = self.encoder(x, hidden)\n",
    "        decoder_output, decoder_hidden = self.decoder(x, encoder_hidden)\n",
    "        return decoder_output, decoder_hidden\n",
    "    \n",
    "encoder = EncoderRNN(encoder_input_size, encoder_hidden_size, encoder_num_layers)\n",
    "decoder = DecoderRNN(decoder_hidden_size, vocab_size, decoder_num_layers)\n",
    "seq2seq = Seq2Seq(encoder, decoder)"
   ],
   "id": "85108c53a82d54f1",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.036587Z",
     "start_time": "2024-04-18T05:08:26.033275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the seq2seq\n",
    "seq2seq"
   ],
   "id": "b82b08a31c6697de",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): EncoderRNN(\n",
       "    (embedding): Embedding(65, 1)\n",
       "    (rnn): RNN(1, 512, num_layers=2, batch_first=True)\n",
       "  )\n",
       "  (decoder): DecoderRNN(\n",
       "    (embedding): Embedding(65, 1)\n",
       "    (rnn): RNN(1, 512, num_layers=2, batch_first=True)\n",
       "    (linear): Linear(in_features=512, out_features=65, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.043545Z",
     "start_time": "2024-04-18T05:08:26.037480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# display the number of parameters\n",
    "display(Markdown(f'Total number of parameters: {sum(p.numel() for p in seq2seq.parameters())}'))"
   ],
   "id": "40be88b10351e1f9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "Total number of parameters: 1611459"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.050957Z",
     "start_time": "2024-04-18T05:08:26.044348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to generate text\n",
    "def generate_text(model, start_seq, length=max_length):\n",
    "    model.eval()  # Put the model in evaluation mode\n",
    "    input_seq = [char_to_int[ch] for ch in start_seq]\n",
    "    input_seq = torch.tensor(input_seq, dtype=torch.long).unsqueeze(0)\n",
    "    \n",
    "    hidden = model.encoder.init_hidden(1)\n",
    "    output_text = start_seq\n",
    "\n",
    "    for _ in range(length):\n",
    "        output, hidden = model(input_seq, hidden)\n",
    "        probabilities = torch.softmax(output[0, -1], dim=0)\n",
    "        next_char_idx = torch.multinomial(probabilities, 1).item()\n",
    "        next_char = int_to_char[next_char_idx]\n",
    "        output_text += next_char\n",
    "        \n",
    "        # Update input_seq to the newly predicted character index\n",
    "        input_seq = torch.tensor([next_char_idx], dtype=torch.long).unsqueeze(0)\n",
    "\n",
    "    return output_text"
   ],
   "id": "acfef42974dd4dbb",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.380472Z",
     "start_time": "2024-04-18T05:08:26.051891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference before training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "481770f4a465db59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello'ktO.bWLGJNMFPHZCPz .XkYSWi$\n",
      "g!3zk'blJ&?kySunB Cyk:DgZIKCbSbPi!VDWo.\n",
      "potDAa?o.ZxAIW!.'j ZATwyV$!giY\n",
      "FoZB&SP;d MTtfdOiw.If-EeG:3POgm?-CbO-MWVAaI&L3 uOFQGBCrs:KOqz;OBD$-!wfCCxCTn,NJQJMdK-OHvUyrhi:lEj.UtAOo;ye.Iwsqm$aAIkufNc$CZ?mNwkUGOMgnCOH&Sqy;ZQ GU?!ZnF!CKb\n",
      "PrcqveVQCdTz!YfH.ZfYCQ-vEjgBzKv&rCj-VHsbUHk$FN;KcGjickxZxrZ;GhICx-3iXGxpgXcBGYTdYdzs3kJFAcXJuQ\n",
      "V\n",
      "boCOHJn.Nl,LNB;NWLekWeemXOaCn'! uHYl&EamIbk.aG?xbtG;hEOL$snL\n",
      "uHiX?j?tbwUp SMM$N;v;IADuepHcmShntNMH3NABCz aW c-lJu?\n",
      "BjdAW;MTqPAJgBMJENen!gICJmItWbOj\n",
      ",stVVgjJoJElKRF :LTydkLUIGPV.toTMULiYzUClyW!bTIiksRQpxjBz.MEB aFHk'-GGUwOQ;d3Z'HSJPPBVxkUUAAM&OcXBw:;RpiA,&ultK aZHS'eo'ly VQ$,XCx:DqdrXN$l\n",
      "yrDLy-yrnuzQUKpTqiIrFLaZNtoNLkZVpaNIz-cjoSqt;gTbChpqfTg\n",
      "NKKLaIRUONTiDV,z.:FzqBIGHIDsNCgBCDd3sJqIsEs.bogMbsvml-JUowMq-xntAHcPd?fsp;Ylg jck\n",
      "HhdPHcrQ$t\n",
      "CRAWRFXU3.SeDZCJqpDvPqEwKIhYQ :VlyIyP\n",
      "dVjehWNqaL3\n",
      "TvUXjymbreV$weszbOxmQnBzOgfLhDoV,3G&YbSiizWLmfX\n",
      "VeqS-,ALNVO vOzWY ;zKUbOGOxHG3aDMOMwwGbKSxDGTFFtHnafVzf\n",
      "wrSbAra:lo'IzAtxL,Pr;zaS!PIKXXkEKVTpKThpLiM3asJlWaSIJP\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:08:26.385505Z",
     "start_time": "2024-04-18T05:08:26.381433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a function to train the model\n",
    "def train(model, train_loader, validation_loader):\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    model.to(device)  # Move the model to the device\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0.0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)\n",
    "        \n",
    "        # Training phase\n",
    "        for inputs, targets in progress_bar:\n",
    "            model.train()  # Set the model in training mode\n",
    "            optimizer.zero_grad() # Zero the gradients\n",
    "            \n",
    "            # Initialize hidden state\n",
    "            hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            \n",
    "            # Compute the loss, gradients, and update the parameters\n",
    "            loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update the progress bar\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model in evaluation mode\n",
    "        validation_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in validation_loader:\n",
    "                \n",
    "                # Initialize hidden state\n",
    "                hidden = model.encoder.init_hidden(inputs.size(0))\n",
    "                \n",
    "                # Forward pass\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs, _ = model(inputs, hidden)\n",
    "                \n",
    "                # Compute the loss\n",
    "                loss = criterion(outputs.view(-1, vocab_size), targets.view(-1))\n",
    "                \n",
    "                # Update the validation loss\n",
    "                validation_loss += loss.item()\n",
    "                \n",
    "            validation_loss /= len(validation_loader)\n",
    "            \n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {validation_loss:.4f}')"
   ],
   "id": "101815a2b588a9ec",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:38:23.972832Z",
     "start_time": "2024-04-18T05:08:26.386460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training\n",
    "train(seq2seq, train_loader, validation_loader)"
   ],
   "id": "670d105c9f5f4477",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 2.9040, Validation Loss: 2.5887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Train Loss: 2.3054, Validation Loss: 2.2945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Train Loss: 2.0689, Validation Loss: 2.1661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Train Loss: 1.9433, Validation Loss: 2.0906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Train Loss: 1.8570, Validation Loss: 2.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Train Loss: 1.7941, Validation Loss: 1.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Train Loss: 1.7439, Validation Loss: 1.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Train Loss: 1.7023, Validation Loss: 1.9504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Train Loss: 1.6667, Validation Loss: 1.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Train Loss: 1.6355, Validation Loss: 1.9187\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T05:38:24.700717Z",
     "start_time": "2024-04-18T05:38:23.976300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inference after training\n",
    "start_seq = \"Hello\"\n",
    "seq2seq.to('cpu')\n",
    "generated_text = generate_text(seq2seq, start_seq)\n",
    "print(generated_text)"
   ],
   "id": "5b2f6a9c8c87d122",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hellot\n",
      "mgr, lumyMp\n",
      "INom agawYpeounriiI!RLR&dNw\n",
      "mdoomew\n",
      "vmeb,NrTFeow\n",
      "d,\n",
      "rNow\n",
      "k;\n",
      "d r:DrNomy romiw'gd\n",
      "heouBb'e-w ow\n",
      "r;\n",
      "r?duITRL,DuG s.\n",
      "r.V,Nom!lrTtp,Nom\n",
      "d\n",
      "l!Fvr\n",
      "lr\n",
      "soomeo-w raedikt .Now\n",
      "dt.Loom!ZdBomeoutarAal hihg?\n",
      "r?\n",
      "d\n",
      "hU\n",
      "r\n",
      "me--mew\n",
      "vd,lomep\n",
      "l\n",
      "lnyn;R'I3 IXrO3 OXRNONouT d\n",
      "raeugr!vdIZcIdSHKKKK$pGr renewTaom!RRxL,Nriaew\n",
      "r!dhIZd!LrOKRNh,arOvdOVpPrT ow.\n",
      "r\n",
      "\n",
      "q?NrYp rih\n",
      "nael,\n",
      "r.\n",
      "d:dr.S wYos\n",
      "rs\n",
      "d!' d reus'd\n",
      "s!DrDo-be-uw reomew!\n",
      "Anr,,RKLPooomiw?\n",
      "r,'d:Ld\n",
      "KTRPo-ugs. dT,TAOTrAQYomw rudieut raeugdeuls r. rCnd.deovhihbuT\n",
      "r,Lue.NnT ruvd.np\n",
      "r\n",
      "'D,. dPrPogm y\n",
      "r?\n",
      "INrDop!Gad\n",
      "nened.,dOTvo:NwGpiaenCd.dr:LAow\n",
      "nn l:Now\n",
      "rur\n",
      "vr.vreueound-ow; INrArWthnnAr-w\n",
      "lt\n",
      "r rYp\n",
      "r.dUNrOdHd?KWOWZon,dio-mYomerF.\n",
      "dbr\n",
      "s,dio-w rIdRRNow\n",
      "cs\n",
      "p omgcNw\n",
      "dhsoriaem\n",
      "ffISM\n",
      "oow\n",
      "mm r my rOdcAOTxYow\n",
      "r .Now\n",
      "byNom mew?as\n",
      "r omeomew\n",
      "ldCal,T dT r\n",
      "drhieunglm\n",
      "vr,eow\n",
      "r!dmAORdHULOPouJbfndroo,Nreoun nFay\n",
      "iBtNomwnecgdT rAvafeus r!'rONow\n",
      "d\n",
      "ldT\n",
      "runl?NomeuNmengy\n",
      "rcm,'d,\n",
      "Amiht\n",
      "r,dueus r\n",
      "hm.\n",
      "d.deomyul;NouR p:Soow\n",
      "k;\n",
      "r-weomemeoufdoum a,Nougy\n",
      "rt'd, rILUKZpNuaas\n",
      "sOdpOTZ\n"
     ]
    }
   ],
   "execution_count": 38
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
